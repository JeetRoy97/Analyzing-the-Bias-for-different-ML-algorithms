{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ques1_lcnn_focal.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "rMX5A5Xp07rm"
      },
      "source": [
        "import keras\n",
        "import tensorflow as tf\n",
        "from typeguard import typechecked\n",
        "\n",
        "\n",
        "class Maxout(keras.layers.Layer):\n",
        "    \"\"\"\n",
        "    Arguments:\n",
        "      num_units: Specifies how many features will remain after maxout\n",
        "        in the `axis` dimension (usually channel).\n",
        "        This must be a factor of number of features.\n",
        "      axis: The dimension where max pooling will be performed. Default is the\n",
        "        last dimension.\n",
        "    Input shape:\n",
        "      nD tensor with shape: `(batch_size, ..., axis_dim, ...)`.\n",
        "    Output shape:\n",
        "      nD tensor with shape: `(batch_size, ..., num_units, ...)`.\n",
        "    Reference : https://github.com/tensorflow/addons/blob/v0.10.0/tensorflow_addons/layers/maxout.py#L22-L90\n",
        "    \"\"\"\n",
        "\n",
        "    @typechecked\n",
        "    def __init__(self, num_units: int, axis: int = -1, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.num_units = num_units\n",
        "        self.axis = axis\n",
        "\n",
        "    def call(self, inputs):\n",
        "        inputs = tf.convert_to_tensor(inputs)\n",
        "        shape = inputs.get_shape().as_list()\n",
        "        # Dealing with batches with arbitrary sizes\n",
        "        for i in range(len(shape)):\n",
        "            if shape[i] is None:\n",
        "                shape[i] = tf.shape(inputs)[i]\n",
        "\n",
        "        num_channels = shape[self.axis]\n",
        "        if not isinstance(num_channels, tf.Tensor) and num_channels % self.num_units:\n",
        "            raise ValueError(\n",
        "                \"number of features({}) is not \" \"a multiple of num_units({})\".format(num_channels, self.num_units)\n",
        "            )\n",
        "\n",
        "        if self.axis < 0:\n",
        "            axis = self.axis + len(shape)\n",
        "        else:\n",
        "            axis = self.axis\n",
        "        assert axis >= 0, \"Find invalid axis: {}\".format(self.axis)\n",
        "\n",
        "        expand_shape = shape[:]\n",
        "        expand_shape[axis] = self.num_units\n",
        "        k = num_channels // self.num_units\n",
        "        expand_shape.insert(axis, k)\n",
        "\n",
        "        outputs = tf.math.reduce_max(tf.reshape(inputs, expand_shape), axis, keepdims=False)\n",
        "        return outputs\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        input_shape = tf.TensorShape(input_shape).as_list()\n",
        "        input_shape[self.axis] = self.num_units\n",
        "        return tf.TensorShape(input_shape)\n",
        "\n",
        "    def get_config(self):\n",
        "        config = {\"num_units\": self.num_units, \"axis\": self.axis}\n",
        "        base_config = super().get_config()\n",
        "        return {**base_config, **config}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZudBlI0Z6Pnx"
      },
      "source": [
        "import tensorflow as tf\n",
        "from keras.layers import Activation, Dense, BatchNormalization, MaxPool2D, Lambda, Input, Flatten, Dropout\n",
        "from keras.layers.convolutional import Conv2D\n",
        "from keras.models import Model\n",
        "from keras.initializers import he_normal\n",
        "\n",
        "#Custom layer\n",
        "\n",
        "\n",
        "#function that return the stuck of Conv2D and MFM\n",
        "def MaxOutConv2D(x, dim, kernel_size, strides, padding='same'):\n",
        "    conv_out = Conv2D(dim, kernel_size=kernel_size, strides=strides, padding=padding)(x)\n",
        "    mfm_out = Maxout(int(dim/2))(conv_out)\n",
        "    return mfm_out\n",
        "\n",
        "\n",
        "#function that return the stuck of FC and MFM\n",
        "def MaxOutDense(x, dim):\n",
        "    dense_out = Dense(dim)(x)\n",
        "    mfm_out = Maxout(int(dim/2))(dense_out)\n",
        "    return mfm_out\n",
        "\n",
        "# this function helps to build LCNN. \n",
        "def build_lcnn(shape, n_label=2):\n",
        "    \"\"\"\n",
        "    Auguments:\n",
        "     shape (list) : \n",
        "      Input shape for LCNN. (Example : [128, 128, 1])\n",
        "     n_label (int) : \n",
        "      Number of label that LCNN should predict.\n",
        "    \"\"\"\n",
        "    \n",
        "    input = Input(shape=shape)\n",
        "\n",
        "    conv2d_1 = MaxOutConv2D(input, 64, kernel_size=5, strides=1, padding='same')\n",
        "    maxpool_1 = MaxPool2D(pool_size=(2, 2), strides=(2,2))(conv2d_1)\n",
        "\n",
        "    conv_2d_2 = MaxOutConv2D(maxpool_1, 64, kernel_size=1, strides=1, padding='same')\n",
        "    batch_norm_2 = BatchNormalization()(conv_2d_2)\n",
        "\n",
        "    conv2d_3 = MaxOutConv2D(batch_norm_2, 96, kernel_size=3, strides=1, padding='same')\n",
        "    maxpool_3 = MaxPool2D(pool_size=(2, 2), strides=(2,2))(conv2d_3)\n",
        "    batch_norm_3 = BatchNormalization()(maxpool_3)\n",
        "\n",
        "    conv_2d_4 = MaxOutConv2D(batch_norm_3, 96, kernel_size=1, strides=1, padding='same')\n",
        "    batch_norm_4 = BatchNormalization()(conv_2d_4)\n",
        "\n",
        "    conv2d_5 = MaxOutConv2D(batch_norm_4, 128, kernel_size=3, strides=1, padding='same')\n",
        "    maxpool_5 = MaxPool2D(pool_size=(2, 2), strides=(2,2))(conv2d_5)\n",
        "\n",
        "    conv_2d_6 = MaxOutConv2D(maxpool_5, 128, kernel_size=1, strides=1, padding='same')\n",
        "    batch_norm_6 = BatchNormalization()(conv_2d_6)\n",
        "\n",
        "    conv_2d_7 = MaxOutConv2D(batch_norm_6, 64, kernel_size=3, strides=1, padding='same')\n",
        "    batch_norm_7 = BatchNormalization()(conv_2d_7)\n",
        "\n",
        "    conv_2d_8 = MaxOutConv2D(batch_norm_7, 64, kernel_size=1, strides=1, padding='same')\n",
        "    batch_norm_8 = BatchNormalization()(conv_2d_8)\n",
        "\n",
        "    conv_2d_9 = MaxOutConv2D(batch_norm_8, 64, kernel_size=3, strides=1, padding='same')\n",
        "    maxpool_9 = MaxPool2D(pool_size=(2, 2), strides=(2,2))(conv_2d_9)\n",
        "    flatten = Flatten()(maxpool_9)\n",
        "\n",
        "    dense_10 = MaxOutDense(flatten, 160)\n",
        "    batch_norm_10 = BatchNormalization()(dense_10)\n",
        "    dropout_10 = Dropout(0.75)(batch_norm_10)\n",
        "\n",
        "    output = Dense(n_label, activation='softmax')(dropout_10)\n",
        "            \n",
        "    return Model(inputs=input, outputs=output)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3n42zQObu9Tk"
      },
      "source": [
        "Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "83Ry591wa2qy",
        "outputId": "b986e38c-752d-4150-c56b-c23871c9bbe4"
      },
      "source": [
        "!git clone https://github.com/ayulockin/faceattributes.git"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'faceattributes'...\n",
            "remote: Enumerating objects: 23407, done.\u001b[K\n",
            "remote: Counting objects: 100% (19/19), done.\u001b[K\n",
            "remote: Compressing objects: 100% (18/18), done.\u001b[K\n",
            "remote: Total 23407 (delta 4), reused 6 (delta 1), pack-reused 23388\u001b[K\n",
            "Receiving objects: 100% (23407/23407), 115.73 MiB | 26.61 MiB/s, done.\n",
            "Resolving deltas: 100% (16/16), done.\n",
            "Checking out files: 100% (23747/23747), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VHHWlq0la7q_",
        "outputId": "39d89f33-3fbe-4138-b156-6c146d9e8fbc"
      },
      "source": [
        "!ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "faceattributes\tsample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hkep7MGOa_-C",
        "outputId": "f5f0c49d-1198-4167-e5f5-34686650c860"
      },
      "source": [
        "%cd faceattributes"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/faceattributes\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6eyQZFmbbhqI",
        "outputId": "8028d474-a11c-4199-84ed-7b954a24ff99"
      },
      "source": [
        "!ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " datasets\n",
            "'EDA of Face Dataset.ipynb'\n",
            " examples\n",
            " face_detector\n",
            " Image1.jpeg\n",
            " images\n",
            " LICENSE\n",
            " main.py\n",
            " prepareUTKFaceData.py\n",
            " README.md\n",
            "'UTK_Face_Attribute_Classifier_with_TF2_0_and_W&B.ipynb'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HdmVG9C1bw9Y",
        "outputId": "03ab70b0-95e4-477b-a2c5-d7a6786dcb6c"
      },
      "source": [
        "import os\n",
        "\n",
        "images = os.listdir('images')\n",
        "print('Total number of images: ', len(images))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total number of images:  23705\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "REYXOXhpbCE4"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn import svm\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "from skimage.transform import rescale, resize, downscale_local_mean\n",
        "from sklearn import datasets, svm, metrics\n",
        "from sklearn.model_selection import train_test_split\n",
        "import warnings\n",
        "import sys\n",
        "import os\n",
        "import shutil\n",
        "from joblib import dump, load\n",
        "import numpy as np\n",
        "import math\n",
        "import torch"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eWNseVm2bCJm"
      },
      "source": [
        "labels = pd.read_csv('datasets/face_dataset.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TSVK_WyCbCMY"
      },
      "source": [
        "labels = labels.sample(frac=1).reset_index(drop=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cz1elP3lbCO-"
      },
      "source": [
        "def groupAge(age):\n",
        "#   Age (0-28 ) as children(28-56) as Young , (56-84) as Adults and (84-116) as Old.\n",
        "    if age>=0 and age<28:\n",
        "        return '0 - 28'\n",
        "    elif age>=28 and age<56:\n",
        "        return '28 - 56'\n",
        "    elif age>=56 and age<84:\n",
        "        return '56 - 24'\n",
        "    elif age>=84 and age<=116:\n",
        "        return '84 - 116'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "USx-TYuXbCRZ"
      },
      "source": [
        " #White, Black, Asian, Indian, and Others\n",
        " def groupRace(race):\n",
        "    if race == 0:\n",
        "        return 'White'\n",
        "    elif race == 1:\n",
        "        return 'Black'\n",
        "    elif race == 2:\n",
        "        return 'Asian'\n",
        "    elif race == 3:\n",
        "        return 'Indian'\n",
        "    else:\n",
        "        return 'Other'\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xa9GJIASbCT9"
      },
      "source": [
        "import numpy as np \n",
        "import cv2\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "#from tensorflow.keras.utils import to_categorical"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eYLbnyNabCWw"
      },
      "source": [
        "def to_categorical(y, num_classes):\n",
        "    \"\"\" 1-hot encodes a tensor \"\"\"\n",
        "    return np.eye(num_classes, dtype='uint8')[y]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "COXli0XmbQ_C"
      },
      "source": [
        "def formatdata(train_count, validation_count, test_count):\n",
        "  partitions = {'train': [],\n",
        "                'validation': [],\n",
        "                'test': []}\n",
        "  labels_dict = {'train_age': [], 'train_gender': [], 'train_ethnicity': [],\n",
        "                 'validation_age': [], 'validation_gender': [], 'validation_ethnicity': [],\n",
        "                 'test_age': [], 'test_gender': [], 'test_ethnicity': []}\n",
        "  random.seed(1)\n",
        "\n",
        "  print(\"[INFO] Preparing train data....\")\n",
        "  for ID in range(train_count):\n",
        "    try:\n",
        "        data = labels.loc[labels['image_id'] == images[ID][:-4]].values\n",
        "        labels_dict['train_age'].append(groupAge(data[0][1]))\n",
        "        labels_dict['train_gender'].append(data[0][2])\n",
        "        labels_dict['train_ethnicity'].append(groupRace(data[0][3]))\n",
        "        partitions['train'].append(images[ID])\n",
        "    except IndexError:\n",
        "        print(\"[ERROR]\", images[ID])\n",
        "        discared_data.append(images[ID])\n",
        "  print(\"[INFO] Done\")\n",
        "\n",
        "  print(\"[INFO] Preparing validation data....\")\n",
        "  for ID in range(train_count, train_count+validation_count):\n",
        "    try:\n",
        "        data = labels.loc[labels['image_id'] == images[ID][:-4]].values\n",
        "        labels_dict['validation_age'].append(groupAge(data[0][1]))\n",
        "        labels_dict['validation_gender'].append(data[0][2])\n",
        "        labels_dict['validation_ethnicity'].append(groupRace(data[0][3]))\n",
        "        partitions['validation'].append(images[ID])\n",
        "    except IndexError:\n",
        "        print(\"[ERROR]\", images[ID])\n",
        "        discared_data.append(images[ID])\n",
        "  print(\"[INFO] Done\")\n",
        "\n",
        "  ## Uncomment to get test split\n",
        "  print(\"[INFO] Preparing test data....\")\n",
        "  for ID in range(train_count+validation_count,train_count+validation_count+test_count):\n",
        "    try:\n",
        "        data = labels.loc[labels['image_id'] == images[ID][:-4]].values\n",
        "        labels_dict['test_age'].append(groupAge(data[0][1]))\n",
        "        labels_dict['test_gender'].append(data[0][2])\n",
        "        labels_dict['test_ethnicity'].append(groupRace(data[0][3]))\n",
        "        partitions['test'].append(images[ID])\n",
        "    except IndexError:\n",
        "        print(\"[ERROR]\", images[ID])\n",
        "        discared_data.append(images[ID])\n",
        "  print(\"[INFO] Done\")\n",
        "\n",
        "  return partitions, labels_dict"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oi1HcJeXbRCG",
        "outputId": "e241bf9b-cbc0-4502-be83-acd72bf4a2e4"
      },
      "source": [
        "# train:validation:test = 70:20:10 = 16596:4742:2370\n",
        "\n",
        "train_count = 16595\n",
        "validation_count = 4741\n",
        "test_count = 2369\n",
        "\n",
        "partitions, labels_dict = formatdata(train_count, validation_count, test_count)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] Preparing train data....\n",
            "[INFO] Done\n",
            "[INFO] Preparing validation data....\n",
            "[INFO] Done\n",
            "[INFO] Preparing test data....\n",
            "[INFO] Done\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vLdNdm9sbRE_",
        "outputId": "3ed7390a-2743-4707-fd78-25dfddfa8484"
      },
      "source": [
        "print(\"[INFO] Training Data\")\n",
        "print(\"Size of train data: \", len(partitions['train']))\n",
        "print(\"Size of age as label: \", len(labels_dict['train_age']))\n",
        "print(\"Size of gender as label: \", len(labels_dict['train_gender']))\n",
        "print(\"Size of ethnicity as label: \", len(labels_dict['train_ethnicity']))\n",
        "print(\"\\n\")\n",
        "print(\"[INFO] Validation Data\")\n",
        "print(\"Size of validation data: \", len(partitions['validation']))\n",
        "print(\"Size of age as label: \", len(labels_dict['validation_age']))\n",
        "print(\"Size of gender as label: \", len(labels_dict['validation_gender']))\n",
        "print(\"Size of ethnicity as label: \", len(labels_dict['validation_ethnicity']))\n",
        "print(\"\\n\")\n",
        "# Uncomment to log test split details\n",
        "print(\"[INFO] Test Data\")\n",
        "print(\"Size of test data: \", len(partitions['test']))\n",
        "print(\"Size of age as label: \", len(labels_dict['test_age']))\n",
        "print(\"Size of gender as label: \", len(labels_dict['test_gender']))\n",
        "print(\"Size of ethnicity as label: \", len(labels_dict['test_ethnicity']))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] Training Data\n",
            "Size of train data:  16595\n",
            "Size of age as label:  16595\n",
            "Size of gender as label:  16595\n",
            "Size of ethnicity as label:  16595\n",
            "\n",
            "\n",
            "[INFO] Validation Data\n",
            "Size of validation data:  4741\n",
            "Size of age as label:  4741\n",
            "Size of gender as label:  4741\n",
            "Size of ethnicity as label:  4741\n",
            "\n",
            "\n",
            "[INFO] Test Data\n",
            "Size of test data:  2369\n",
            "Size of age as label:  2369\n",
            "Size of gender as label:  2369\n",
            "Size of ethnicity as label:  2369\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FGY5APu7bRHz",
        "outputId": "7c32ebcc-c7ee-45fc-9591-21f7349c3766"
      },
      "source": [
        "import imageio\n",
        "def loadImages(images, imagesPath):\n",
        "    print(\"[INFO] Loading....\")\n",
        "    X = []\n",
        "    count = 0\n",
        "    for image in images:\n",
        "        if count%1000==0:\n",
        "            print(\"[INFO] {} images loaded\".format(count))\n",
        "        img = imageio.imread(imagesPath+'/'+image)\n",
        "        #img = np.array(img)\n",
        "        #resized_images = rescale(img, 0.5, anti_aliasing=False)\n",
        "        resized_images = cv2.resize(img,(32,32))\n",
        "        X.append(resized_images)\n",
        "        count+=1\n",
        "    print(\"[INFO] Done\")\n",
        "    return np.array(X)\n",
        "\n",
        "print(\"[INFO] Training Data\")\n",
        "trainX = loadImages(partitions['train'], 'images/')\n",
        "print(\"[INFO] Validation Data\")\n",
        "validationX = loadImages(partitions['validation'], 'images/')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] Training Data\n",
            "[INFO] Loading....\n",
            "[INFO] 0 images loaded\n",
            "[INFO] 1000 images loaded\n",
            "[INFO] 2000 images loaded\n",
            "[INFO] 3000 images loaded\n",
            "[INFO] 4000 images loaded\n",
            "[INFO] 5000 images loaded\n",
            "[INFO] 6000 images loaded\n",
            "[INFO] 7000 images loaded\n",
            "[INFO] 8000 images loaded\n",
            "[INFO] 9000 images loaded\n",
            "[INFO] 10000 images loaded\n",
            "[INFO] 11000 images loaded\n",
            "[INFO] 12000 images loaded\n",
            "[INFO] 13000 images loaded\n",
            "[INFO] 14000 images loaded\n",
            "[INFO] 15000 images loaded\n",
            "[INFO] 16000 images loaded\n",
            "[INFO] Done\n",
            "[INFO] Validation Data\n",
            "[INFO] Loading....\n",
            "[INFO] 0 images loaded\n",
            "[INFO] 1000 images loaded\n",
            "[INFO] 2000 images loaded\n",
            "[INFO] 3000 images loaded\n",
            "[INFO] 4000 images loaded\n",
            "[INFO] Done\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T_DuDkzVbRKM",
        "outputId": "593f2089-28db-4be5-fdda-1ff215204358"
      },
      "source": [
        "print(\"[INFO] test Data\")\n",
        "testX = loadImages(partitions['test'], 'images/')\n",
        "testX = testX/255.0\n",
        "# testX_reshape = testX.flatten().reshape(testX.shape[0],testX.shape[1]* testX.shape[2]* testX.shape[3])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] test Data\n",
            "[INFO] Loading....\n",
            "[INFO] 0 images loaded\n",
            "[INFO] 1000 images loaded\n",
            "[INFO] 2000 images loaded\n",
            "[INFO] Done\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d7WvLJg7bRMm"
      },
      "source": [
        "trainX = trainX/255.0\n",
        "validationX = validationX/255.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8H5UHPsmowif",
        "outputId": "3783d76e-2a4e-4192-eaa2-b2370f5c68f1"
      },
      "source": [
        "trainX.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(16595, 32, 32, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aEId182BqRv9",
        "outputId": "e7108845-7a3b-43bc-e234-ebc091a992b0"
      },
      "source": [
        "testX.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2369, 32, 32, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OvTISByhbRPO"
      },
      "source": [
        "trainY = {\n",
        "    'gender': np.array(labels_dict['train_gender']),\n",
        "    'ethnicity': np.array(labels_dict['train_ethnicity']),\n",
        "    'age': np.array(labels_dict['train_age'])\n",
        "}\n",
        "\n",
        "validationY = {\n",
        "    'gender': np.array(labels_dict['validation_gender']),\n",
        "    'ethnicity': np.array(labels_dict['validation_ethnicity']),\n",
        "    'age': np.array(labels_dict['validation_age'])\n",
        "}\n",
        "testY = {\n",
        "    'gender': np.array(labels_dict['test_gender']),\n",
        "    'ethnicity': np.array(labels_dict['test_ethnicity']),\n",
        "    'age': np.array(labels_dict['test_age'])\n",
        "}\n",
        "\n",
        "trainY['gender'] = trainY['gender'].reshape(trainY['gender'].shape[0])\n",
        "validationY['gender'] = validationY['gender'].reshape(validationY['gender'].shape[0])\n",
        "sample_test = testY['gender']\n",
        "#testY['gender'] = testY['gender'].reshape(testY['gender'].shape[0], 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E6zAr9S9cQfp",
        "outputId": "76c78f58-9167-4ad3-fdb8-b88097c37b69"
      },
      "source": [
        "print('Training labels')\n",
        "print('[INFO] Shape of gender label: ', trainY['gender'].shape)\n",
        "print('[INFO] Shape of ethnicity label: ', trainY['ethnicity'].shape)\n",
        "print('[INFO] Shape of age label: ', trainY['age'].shape)\n",
        "print('\\nValidation labels')\n",
        "print('[INFO] Shape of gender label: ', validationY['gender'].shape)\n",
        "print('[INFO] Shape of ethnicity label: ', validationY['ethnicity'].shape)\n",
        "print('[INFO] Shape of age label: ', validationY['age'].shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training labels\n",
            "[INFO] Shape of gender label:  (16595,)\n",
            "[INFO] Shape of ethnicity label:  (16595,)\n",
            "[INFO] Shape of age label:  (16595,)\n",
            "\n",
            "Validation labels\n",
            "[INFO] Shape of gender label:  (4741,)\n",
            "[INFO] Shape of ethnicity label:  (4741,)\n",
            "[INFO] Shape of age label:  (4741,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f2wViEvlq5V5"
      },
      "source": [
        "from tensorflow.keras.utils import to_categorical\n",
        "trainY['gender'] = to_categorical(trainY['gender'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-frCWsRccQj2",
        "outputId": "ef191002-ecae-4cf0-c9e5-02984002afc7"
      },
      "source": [
        "trainY['gender'].shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(16595, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bwr4tXbNcQoY"
      },
      "source": [
        "testY['gender'] = to_categorical(testY['gender'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DdXrpe1SB3iO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "054ad2a8-f7e8-4aca-e699-3c077660d877"
      },
      "source": [
        "testY['gender'].shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2369, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CjwKIjE_OrL4"
      },
      "source": [
        "import numpy\n",
        "x_train = trainX\n",
        "x_test = testX\n",
        "y_train_gender = trainY['gender']\n",
        "y_test_gender = testY['gender']\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d0kyVKsEs-wn",
        "outputId": "4b164f13-2647-474f-b4a0-6392fb4c87a5"
      },
      "source": [
        "y_test_gender.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2369, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WeSny_QWOmWY",
        "outputId": "11c55c4b-9e3f-40c7-e1a3-18b095a8ccdc"
      },
      "source": [
        "x_train.shape,y_train_gender.shape,x_test.shape,y_test_gender.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((16595, 32, 32, 3), (16595, 2), (2369, 32, 32, 3), (2369, 2))"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4z9TRLcJRzpy"
      },
      "source": [
        "# Focal loss"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D44Alj2ERy-h"
      },
      "source": [
        "from tensorflow.keras import backend as K\n",
        "import tensorflow as tf\n",
        "\n",
        "# Compatible with tensorflow backend\n",
        "\n",
        "def focal_loss(gamma=2., alpha=.25):\n",
        "\tdef focal_loss_fixed(y_true, y_pred):\n",
        "\t\tpt_1 = tf.where(tf.equal(y_true, 1), y_pred, tf.ones_like(y_pred))\n",
        "\t\tpt_0 = tf.where(tf.equal(y_true, 0), y_pred, tf.zeros_like(y_pred))\n",
        "\t\treturn -K.mean(alpha * K.pow(1. - pt_1, gamma) * K.log(pt_1+K.epsilon())) - K.mean((1 - alpha) * K.pow(pt_0, gamma) * K.log(1. - pt_0 + K.epsilon()))\n",
        "\treturn focal_loss_fixed"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M3XJF0e6v9O7"
      },
      "source": [
        "Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0PtiVeZKnPjP"
      },
      "source": [
        "import numpy as np\n",
        "from keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "\n",
        "lr = 0.001\n",
        "epochs = 400\n",
        "batch_size =64\n",
        "x_train, y_train = x_train,y_train_gender\n",
        "x_test, y_test = x_test,y_test_gender\n",
        "input_shape = x_train.shape[1:]\n",
        "lcnn = build_lcnn(input_shape, n_label=2)\n",
        "lcnn.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=lr), loss=[focal_loss(alpha=.25, gamma=2)], metrics=['accuracy'])\n",
        "es = EarlyStopping(monitor='val_loss', patience=5 , verbose=1)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V7ZFAM3LQThj",
        "outputId": "909be730-81f2-4843-c145-7d20e8900f0a"
      },
      "source": [
        "x_train.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(16595, 32, 32, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aLmZ2qazExUG",
        "outputId": "a025016e-69b9-46ce-baad-419da3f806b8"
      },
      "source": [
        "history = lcnn.fit(x_train, y_train, epochs=epochs, batch_size = 128, validation_split=0.3)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/400\n",
            "91/91 [==============================] - 37s 55ms/step - loss: 0.4125 - accuracy: 0.5723 - val_loss: 0.0963 - val_accuracy: 0.5306\n",
            "Epoch 2/400\n",
            "91/91 [==============================] - 4s 43ms/step - loss: 0.1860 - accuracy: 0.6117 - val_loss: 0.0965 - val_accuracy: 0.5302\n",
            "Epoch 3/400\n",
            "91/91 [==============================] - 4s 43ms/step - loss: 0.1242 - accuracy: 0.6775 - val_loss: 0.0826 - val_accuracy: 0.6166\n",
            "Epoch 4/400\n",
            "91/91 [==============================] - 4s 44ms/step - loss: 0.1016 - accuracy: 0.7237 - val_loss: 0.0817 - val_accuracy: 0.6007\n",
            "Epoch 5/400\n",
            "91/91 [==============================] - 4s 43ms/step - loss: 0.0797 - accuracy: 0.7852 - val_loss: 0.0645 - val_accuracy: 0.7602\n",
            "Epoch 6/400\n",
            "91/91 [==============================] - 4s 43ms/step - loss: 0.0590 - accuracy: 0.8135 - val_loss: 0.0653 - val_accuracy: 0.7333\n",
            "Epoch 7/400\n",
            "91/91 [==============================] - 4s 43ms/step - loss: 0.0475 - accuracy: 0.8453 - val_loss: 0.0481 - val_accuracy: 0.8357\n",
            "Epoch 8/400\n",
            "91/91 [==============================] - 4s 43ms/step - loss: 0.0414 - accuracy: 0.8673 - val_loss: 0.0464 - val_accuracy: 0.8413\n",
            "Epoch 9/400\n",
            "91/91 [==============================] - 4s 44ms/step - loss: 0.0373 - accuracy: 0.8823 - val_loss: 0.0614 - val_accuracy: 0.7975\n",
            "Epoch 10/400\n",
            "91/91 [==============================] - 4s 43ms/step - loss: 0.0341 - accuracy: 0.8920 - val_loss: 0.0514 - val_accuracy: 0.8389\n",
            "Epoch 11/400\n",
            "91/91 [==============================] - 4s 43ms/step - loss: 0.0303 - accuracy: 0.9027 - val_loss: 0.0489 - val_accuracy: 0.8572\n",
            "Epoch 12/400\n",
            "91/91 [==============================] - 4s 43ms/step - loss: 0.0274 - accuracy: 0.9161 - val_loss: 0.0513 - val_accuracy: 0.8468\n",
            "Epoch 13/400\n",
            "91/91 [==============================] - 4s 44ms/step - loss: 0.0253 - accuracy: 0.9217 - val_loss: 0.0601 - val_accuracy: 0.8329\n",
            "Epoch 14/400\n",
            "91/91 [==============================] - 4s 43ms/step - loss: 0.0233 - accuracy: 0.9287 - val_loss: 0.0598 - val_accuracy: 0.8429\n",
            "Epoch 15/400\n",
            "91/91 [==============================] - 4s 43ms/step - loss: 0.0194 - accuracy: 0.9424 - val_loss: 0.0638 - val_accuracy: 0.8405\n",
            "Epoch 16/400\n",
            "91/91 [==============================] - 4s 43ms/step - loss: 0.0195 - accuracy: 0.9398 - val_loss: 0.0728 - val_accuracy: 0.8439\n",
            "Epoch 17/400\n",
            "91/91 [==============================] - 4s 43ms/step - loss: 0.0181 - accuracy: 0.9484 - val_loss: 0.0767 - val_accuracy: 0.8413\n",
            "Epoch 18/400\n",
            "91/91 [==============================] - 4s 43ms/step - loss: 0.0177 - accuracy: 0.9481 - val_loss: 0.0746 - val_accuracy: 0.8287\n",
            "Epoch 19/400\n",
            "91/91 [==============================] - 4s 43ms/step - loss: 0.0147 - accuracy: 0.9588 - val_loss: 0.0860 - val_accuracy: 0.8212\n",
            "Epoch 20/400\n",
            "91/91 [==============================] - 4s 44ms/step - loss: 0.0120 - accuracy: 0.9691 - val_loss: 0.1251 - val_accuracy: 0.7907\n",
            "Epoch 21/400\n",
            "91/91 [==============================] - 4s 44ms/step - loss: 0.0153 - accuracy: 0.9569 - val_loss: 0.0705 - val_accuracy: 0.8460\n",
            "Epoch 22/400\n",
            "91/91 [==============================] - 4s 43ms/step - loss: 0.0116 - accuracy: 0.9688 - val_loss: 0.0861 - val_accuracy: 0.8393\n",
            "Epoch 23/400\n",
            "91/91 [==============================] - 4s 44ms/step - loss: 0.0119 - accuracy: 0.9675 - val_loss: 0.0853 - val_accuracy: 0.8393\n",
            "Epoch 24/400\n",
            "91/91 [==============================] - 4s 44ms/step - loss: 0.0102 - accuracy: 0.9712 - val_loss: 0.0886 - val_accuracy: 0.8556\n",
            "Epoch 25/400\n",
            "91/91 [==============================] - 4s 43ms/step - loss: 0.0123 - accuracy: 0.9670 - val_loss: 0.0793 - val_accuracy: 0.8686\n",
            "Epoch 26/400\n",
            "91/91 [==============================] - 4s 43ms/step - loss: 0.0113 - accuracy: 0.9703 - val_loss: 0.0827 - val_accuracy: 0.8524\n",
            "Epoch 27/400\n",
            "91/91 [==============================] - 4s 43ms/step - loss: 0.0090 - accuracy: 0.9763 - val_loss: 0.0985 - val_accuracy: 0.8496\n",
            "Epoch 28/400\n",
            "91/91 [==============================] - 4s 43ms/step - loss: 0.0090 - accuracy: 0.9754 - val_loss: 0.0890 - val_accuracy: 0.8454\n",
            "Epoch 29/400\n",
            "91/91 [==============================] - 4s 43ms/step - loss: 0.0094 - accuracy: 0.9779 - val_loss: 0.0952 - val_accuracy: 0.8439\n",
            "Epoch 30/400\n",
            "91/91 [==============================] - 4s 43ms/step - loss: 0.0112 - accuracy: 0.9700 - val_loss: 0.0897 - val_accuracy: 0.8379\n",
            "Epoch 31/400\n",
            "91/91 [==============================] - 4s 43ms/step - loss: 0.0087 - accuracy: 0.9761 - val_loss: 0.0818 - val_accuracy: 0.8582\n",
            "Epoch 32/400\n",
            "91/91 [==============================] - 4s 43ms/step - loss: 0.0062 - accuracy: 0.9858 - val_loss: 0.0869 - val_accuracy: 0.8660\n",
            "Epoch 33/400\n",
            "91/91 [==============================] - 4s 43ms/step - loss: 0.0060 - accuracy: 0.9845 - val_loss: 0.1025 - val_accuracy: 0.8514\n",
            "Epoch 34/400\n",
            "91/91 [==============================] - 4s 43ms/step - loss: 0.0094 - accuracy: 0.9742 - val_loss: 0.1488 - val_accuracy: 0.8098\n",
            "Epoch 35/400\n",
            "91/91 [==============================] - 4s 44ms/step - loss: 0.0090 - accuracy: 0.9755 - val_loss: 0.0852 - val_accuracy: 0.8614\n",
            "Epoch 36/400\n",
            "91/91 [==============================] - 4s 43ms/step - loss: 0.0058 - accuracy: 0.9865 - val_loss: 0.1033 - val_accuracy: 0.8606\n",
            "Epoch 37/400\n",
            "91/91 [==============================] - 4s 43ms/step - loss: 0.0091 - accuracy: 0.9771 - val_loss: 0.0845 - val_accuracy: 0.8578\n",
            "Epoch 38/400\n",
            "91/91 [==============================] - 4s 43ms/step - loss: 0.0064 - accuracy: 0.9847 - val_loss: 0.0850 - val_accuracy: 0.8658\n",
            "Epoch 39/400\n",
            "91/91 [==============================] - 4s 43ms/step - loss: 0.0030 - accuracy: 0.9925 - val_loss: 0.1023 - val_accuracy: 0.8626\n",
            "Epoch 40/400\n",
            "91/91 [==============================] - 4s 43ms/step - loss: 0.0061 - accuracy: 0.9865 - val_loss: 0.1056 - val_accuracy: 0.8484\n",
            "Epoch 41/400\n",
            "91/91 [==============================] - 4s 43ms/step - loss: 0.0089 - accuracy: 0.9751 - val_loss: 0.0929 - val_accuracy: 0.8518\n",
            "Epoch 42/400\n",
            "91/91 [==============================] - 4s 43ms/step - loss: 0.0070 - accuracy: 0.9830 - val_loss: 0.0963 - val_accuracy: 0.8598\n",
            "Epoch 43/400\n",
            "91/91 [==============================] - 4s 44ms/step - loss: 0.0064 - accuracy: 0.9830 - val_loss: 0.0990 - val_accuracy: 0.8632\n",
            "Epoch 44/400\n",
            "91/91 [==============================] - 4s 43ms/step - loss: 0.0069 - accuracy: 0.9834 - val_loss: 0.1070 - val_accuracy: 0.8379\n",
            "Epoch 45/400\n",
            "91/91 [==============================] - 4s 43ms/step - loss: 0.0069 - accuracy: 0.9810 - val_loss: 0.1011 - val_accuracy: 0.8488\n",
            "Epoch 46/400\n",
            "91/91 [==============================] - 4s 43ms/step - loss: 0.0048 - accuracy: 0.9874 - val_loss: 0.0932 - val_accuracy: 0.8632\n",
            "Epoch 47/400\n",
            "91/91 [==============================] - 4s 43ms/step - loss: 0.0068 - accuracy: 0.9820 - val_loss: 0.0994 - val_accuracy: 0.8458\n",
            "Epoch 48/400\n",
            "91/91 [==============================] - 4s 43ms/step - loss: 0.0059 - accuracy: 0.9861 - val_loss: 0.1170 - val_accuracy: 0.8431\n",
            "Epoch 49/400\n",
            "91/91 [==============================] - 4s 43ms/step - loss: 0.0069 - accuracy: 0.9839 - val_loss: 0.0920 - val_accuracy: 0.8431\n",
            "Epoch 50/400\n",
            "91/91 [==============================] - 4s 44ms/step - loss: 0.0049 - accuracy: 0.9876 - val_loss: 0.0999 - val_accuracy: 0.8626\n",
            "Epoch 51/400\n",
            "91/91 [==============================] - 4s 43ms/step - loss: 0.0033 - accuracy: 0.9929 - val_loss: 0.1301 - val_accuracy: 0.8562\n",
            "Epoch 52/400\n",
            "91/91 [==============================] - 4s 43ms/step - loss: 0.0093 - accuracy: 0.9776 - val_loss: 0.0700 - val_accuracy: 0.8500\n",
            "Epoch 53/400\n",
            "91/91 [==============================] - 4s 43ms/step - loss: 0.0055 - accuracy: 0.9863 - val_loss: 0.0930 - val_accuracy: 0.8556\n",
            "Epoch 54/400\n",
            "91/91 [==============================] - 4s 43ms/step - loss: 0.0039 - accuracy: 0.9895 - val_loss: 0.1156 - val_accuracy: 0.8423\n",
            "Epoch 55/400\n",
            "91/91 [==============================] - 4s 44ms/step - loss: 0.0054 - accuracy: 0.9865 - val_loss: 0.0871 - val_accuracy: 0.8634\n",
            "Epoch 56/400\n",
            "91/91 [==============================] - 4s 44ms/step - loss: 0.0052 - accuracy: 0.9873 - val_loss: 0.0980 - val_accuracy: 0.8612\n",
            "Epoch 57/400\n",
            "91/91 [==============================] - 4s 44ms/step - loss: 0.0044 - accuracy: 0.9895 - val_loss: 0.0913 - val_accuracy: 0.8709\n",
            "Epoch 58/400\n",
            "91/91 [==============================] - 4s 44ms/step - loss: 0.0033 - accuracy: 0.9919 - val_loss: 0.1165 - val_accuracy: 0.8703\n",
            "Epoch 59/400\n",
            "91/91 [==============================] - 4s 44ms/step - loss: 0.0070 - accuracy: 0.9828 - val_loss: 0.1077 - val_accuracy: 0.8466\n",
            "Epoch 60/400\n",
            "91/91 [==============================] - 4s 43ms/step - loss: 0.0058 - accuracy: 0.9859 - val_loss: 0.1019 - val_accuracy: 0.8695\n",
            "Epoch 61/400\n",
            "91/91 [==============================] - 4s 44ms/step - loss: 0.0039 - accuracy: 0.9906 - val_loss: 0.1213 - val_accuracy: 0.8170\n",
            "Epoch 62/400\n",
            "91/91 [==============================] - 4s 44ms/step - loss: 0.0038 - accuracy: 0.9904 - val_loss: 0.1183 - val_accuracy: 0.8550\n",
            "Epoch 63/400\n",
            "91/91 [==============================] - 4s 44ms/step - loss: 0.0067 - accuracy: 0.9826 - val_loss: 0.0912 - val_accuracy: 0.8508\n",
            "Epoch 64/400\n",
            "91/91 [==============================] - 4s 44ms/step - loss: 0.0042 - accuracy: 0.9901 - val_loss: 0.1069 - val_accuracy: 0.8658\n",
            "Epoch 65/400\n",
            "91/91 [==============================] - 4s 44ms/step - loss: 0.0035 - accuracy: 0.9914 - val_loss: 0.1030 - val_accuracy: 0.8630\n",
            "Epoch 66/400\n",
            "91/91 [==============================] - 4s 44ms/step - loss: 0.0034 - accuracy: 0.9927 - val_loss: 0.1035 - val_accuracy: 0.8666\n",
            "Epoch 67/400\n",
            "91/91 [==============================] - 4s 44ms/step - loss: 0.0051 - accuracy: 0.9879 - val_loss: 0.1054 - val_accuracy: 0.8526\n",
            "Epoch 68/400\n",
            "91/91 [==============================] - 4s 43ms/step - loss: 0.0073 - accuracy: 0.9798 - val_loss: 0.0896 - val_accuracy: 0.8538\n",
            "Epoch 69/400\n",
            "91/91 [==============================] - 4s 43ms/step - loss: 0.0046 - accuracy: 0.9895 - val_loss: 0.1004 - val_accuracy: 0.8628\n",
            "Epoch 70/400\n",
            "91/91 [==============================] - 4s 43ms/step - loss: 0.0046 - accuracy: 0.9898 - val_loss: 0.1004 - val_accuracy: 0.8642\n",
            "Epoch 71/400\n",
            "91/91 [==============================] - 4s 44ms/step - loss: 0.0032 - accuracy: 0.9917 - val_loss: 0.1083 - val_accuracy: 0.8682\n",
            "Epoch 72/400\n",
            "91/91 [==============================] - 4s 44ms/step - loss: 0.0053 - accuracy: 0.9871 - val_loss: 0.1080 - val_accuracy: 0.8570\n",
            "Epoch 73/400\n",
            "91/91 [==============================] - 4s 44ms/step - loss: 0.0046 - accuracy: 0.9882 - val_loss: 0.0968 - val_accuracy: 0.8695\n",
            "Epoch 74/400\n",
            "91/91 [==============================] - 4s 44ms/step - loss: 0.0032 - accuracy: 0.9924 - val_loss: 0.1004 - val_accuracy: 0.8604\n",
            "Epoch 75/400\n",
            "91/91 [==============================] - 4s 44ms/step - loss: 0.0032 - accuracy: 0.9920 - val_loss: 0.1061 - val_accuracy: 0.8652\n",
            "Epoch 76/400\n",
            "91/91 [==============================] - 4s 43ms/step - loss: 0.0044 - accuracy: 0.9884 - val_loss: 0.1081 - val_accuracy: 0.8532\n",
            "Epoch 77/400\n",
            "91/91 [==============================] - 4s 44ms/step - loss: 0.0044 - accuracy: 0.9897 - val_loss: 0.1083 - val_accuracy: 0.8532\n",
            "Epoch 78/400\n",
            "91/91 [==============================] - 4s 44ms/step - loss: 0.0040 - accuracy: 0.9909 - val_loss: 0.1042 - val_accuracy: 0.8676\n",
            "Epoch 79/400\n",
            "91/91 [==============================] - 4s 44ms/step - loss: 0.0054 - accuracy: 0.9863 - val_loss: 0.0878 - val_accuracy: 0.8719\n",
            "Epoch 80/400\n",
            "91/91 [==============================] - 4s 43ms/step - loss: 0.0032 - accuracy: 0.9932 - val_loss: 0.1023 - val_accuracy: 0.8767\n",
            "Epoch 81/400\n",
            "91/91 [==============================] - 4s 43ms/step - loss: 0.0026 - accuracy: 0.9947 - val_loss: 0.1072 - val_accuracy: 0.8765\n",
            "Epoch 82/400\n",
            "91/91 [==============================] - 4s 44ms/step - loss: 0.0041 - accuracy: 0.9904 - val_loss: 0.0975 - val_accuracy: 0.8500\n",
            "Epoch 83/400\n",
            "91/91 [==============================] - 4s 44ms/step - loss: 0.0069 - accuracy: 0.9825 - val_loss: 0.1077 - val_accuracy: 0.8506\n",
            "Epoch 84/400\n",
            "91/91 [==============================] - 4s 44ms/step - loss: 0.0031 - accuracy: 0.9923 - val_loss: 0.1153 - val_accuracy: 0.8632\n",
            "Epoch 85/400\n",
            "91/91 [==============================] - 4s 44ms/step - loss: 0.0044 - accuracy: 0.9892 - val_loss: 0.0944 - val_accuracy: 0.8753\n",
            "Epoch 86/400\n",
            "91/91 [==============================] - 4s 44ms/step - loss: 0.0024 - accuracy: 0.9944 - val_loss: 0.1082 - val_accuracy: 0.8680\n",
            "Epoch 87/400\n",
            "91/91 [==============================] - 4s 44ms/step - loss: 0.0019 - accuracy: 0.9969 - val_loss: 0.1037 - val_accuracy: 0.8741\n",
            "Epoch 88/400\n",
            "91/91 [==============================] - 4s 43ms/step - loss: 0.0011 - accuracy: 0.9981 - val_loss: 0.1133 - val_accuracy: 0.8757\n",
            "Epoch 89/400\n",
            "91/91 [==============================] - 4s 43ms/step - loss: 0.0014 - accuracy: 0.9980 - val_loss: 0.1059 - val_accuracy: 0.8747\n",
            "Epoch 90/400\n",
            "91/91 [==============================] - 4s 43ms/step - loss: 0.0015 - accuracy: 0.9968 - val_loss: 0.1118 - val_accuracy: 0.8723\n",
            "Epoch 91/400\n",
            "91/91 [==============================] - 4s 43ms/step - loss: 0.0022 - accuracy: 0.9960 - val_loss: 0.1101 - val_accuracy: 0.8688\n",
            "Epoch 92/400\n",
            "91/91 [==============================] - 4s 44ms/step - loss: 0.0015 - accuracy: 0.9975 - val_loss: 0.1088 - val_accuracy: 0.8765\n",
            "Epoch 93/400\n",
            "91/91 [==============================] - 4s 44ms/step - loss: 9.3448e-04 - accuracy: 0.9981 - val_loss: 0.1143 - val_accuracy: 0.8781\n",
            "Epoch 94/400\n",
            "91/91 [==============================] - 4s 44ms/step - loss: 9.6395e-04 - accuracy: 0.9979 - val_loss: 0.1141 - val_accuracy: 0.8813\n",
            "Epoch 95/400\n",
            "91/91 [==============================] - 4s 44ms/step - loss: 0.0013 - accuracy: 0.9979 - val_loss: 0.1226 - val_accuracy: 0.8715\n",
            "Epoch 96/400\n",
            "91/91 [==============================] - 4s 44ms/step - loss: 0.0010 - accuracy: 0.9982 - val_loss: 0.1117 - val_accuracy: 0.8773\n",
            "Epoch 97/400\n",
            "91/91 [==============================] - 4s 44ms/step - loss: 8.4805e-04 - accuracy: 0.9983 - val_loss: 0.1108 - val_accuracy: 0.8755\n",
            "Epoch 98/400\n",
            "91/91 [==============================] - 4s 44ms/step - loss: 8.3907e-04 - accuracy: 0.9978 - val_loss: 0.1373 - val_accuracy: 0.8604\n",
            "Epoch 99/400\n",
            "91/91 [==============================] - 4s 44ms/step - loss: 0.0035 - accuracy: 0.9934 - val_loss: 0.0807 - val_accuracy: 0.8574\n",
            "Epoch 100/400\n",
            "91/91 [==============================] - 4s 44ms/step - loss: 0.0086 - accuracy: 0.9779 - val_loss: 0.0775 - val_accuracy: 0.8458\n",
            "Epoch 101/400\n",
            "91/91 [==============================] - 4s 43ms/step - loss: 0.0080 - accuracy: 0.9792 - val_loss: 0.1086 - val_accuracy: 0.8604\n",
            "Epoch 102/400\n",
            "91/91 [==============================] - 4s 44ms/step - loss: 0.0064 - accuracy: 0.9827 - val_loss: 0.0868 - val_accuracy: 0.8540\n",
            "Epoch 103/400\n",
            "91/91 [==============================] - 4s 44ms/step - loss: 0.0053 - accuracy: 0.9865 - val_loss: 0.0994 - val_accuracy: 0.8576\n",
            "Epoch 104/400\n",
            "91/91 [==============================] - 4s 43ms/step - loss: 0.0044 - accuracy: 0.9881 - val_loss: 0.1098 - val_accuracy: 0.8620\n",
            "Epoch 105/400\n",
            "91/91 [==============================] - 4s 44ms/step - loss: 0.0038 - accuracy: 0.9917 - val_loss: 0.1038 - val_accuracy: 0.8624\n",
            "Epoch 106/400\n",
            "91/91 [==============================] - 4s 43ms/step - loss: 0.0034 - accuracy: 0.9912 - val_loss: 0.1060 - val_accuracy: 0.8725\n",
            "Epoch 107/400\n",
            "91/91 [==============================] - 4s 44ms/step - loss: 0.0026 - accuracy: 0.9929 - val_loss: 0.1129 - val_accuracy: 0.8566\n",
            "Epoch 108/400\n",
            "91/91 [==============================] - 4s 44ms/step - loss: 0.0041 - accuracy: 0.9900 - val_loss: 0.1049 - val_accuracy: 0.8701\n",
            "Epoch 109/400\n",
            "91/91 [==============================] - 4s 43ms/step - loss: 0.0037 - accuracy: 0.9908 - val_loss: 0.0988 - val_accuracy: 0.8638\n",
            "Epoch 110/400\n",
            "91/91 [==============================] - 4s 44ms/step - loss: 0.0040 - accuracy: 0.9910 - val_loss: 0.0921 - val_accuracy: 0.8574\n",
            "Epoch 111/400\n",
            "91/91 [==============================] - 4s 44ms/step - loss: 0.0027 - accuracy: 0.9939 - val_loss: 0.1214 - val_accuracy: 0.8550\n",
            "Epoch 112/400\n",
            "91/91 [==============================] - 4s 44ms/step - loss: 0.0024 - accuracy: 0.9947 - val_loss: 0.1061 - val_accuracy: 0.8717\n",
            "Epoch 113/400\n",
            "91/91 [==============================] - 4s 44ms/step - loss: 0.0022 - accuracy: 0.9954 - val_loss: 0.1023 - val_accuracy: 0.8646\n",
            "Epoch 114/400\n",
            "91/91 [==============================] - 4s 44ms/step - loss: 0.0017 - accuracy: 0.9963 - val_loss: 0.1128 - val_accuracy: 0.8699\n",
            "Epoch 115/400\n",
            "91/91 [==============================] - 4s 44ms/step - loss: 0.0010 - accuracy: 0.9982 - val_loss: 0.1252 - val_accuracy: 0.8775\n",
            "Epoch 116/400\n",
            "91/91 [==============================] - 4s 44ms/step - loss: 0.0014 - accuracy: 0.9969 - val_loss: 0.1144 - val_accuracy: 0.8775\n",
            "Epoch 117/400\n",
            "91/91 [==============================] - 4s 43ms/step - loss: 7.7964e-04 - accuracy: 0.9979 - val_loss: 0.1287 - val_accuracy: 0.8755\n",
            "Epoch 118/400\n",
            "91/91 [==============================] - 4s 43ms/step - loss: 7.7346e-04 - accuracy: 0.9983 - val_loss: 0.1342 - val_accuracy: 0.8699\n",
            "Epoch 119/400\n",
            "91/91 [==============================] - 4s 44ms/step - loss: 8.3727e-04 - accuracy: 0.9986 - val_loss: 0.1111 - val_accuracy: 0.8763\n",
            "Epoch 120/400\n",
            "91/91 [==============================] - 4s 44ms/step - loss: 0.0019 - accuracy: 0.9950 - val_loss: 0.1179 - val_accuracy: 0.8713\n",
            "Epoch 121/400\n",
            "91/91 [==============================] - 4s 44ms/step - loss: 0.0043 - accuracy: 0.9903 - val_loss: 0.1143 - val_accuracy: 0.8032\n",
            "Epoch 122/400\n",
            "91/91 [==============================] - 4s 44ms/step - loss: 0.0073 - accuracy: 0.9805 - val_loss: 0.0855 - val_accuracy: 0.8672\n",
            "Epoch 123/400\n",
            "91/91 [==============================] - 4s 44ms/step - loss: 0.0041 - accuracy: 0.9898 - val_loss: 0.1080 - val_accuracy: 0.8686\n",
            "Epoch 124/400\n",
            "91/91 [==============================] - 4s 44ms/step - loss: 0.0050 - accuracy: 0.9872 - val_loss: 0.1011 - val_accuracy: 0.8721\n",
            "Epoch 125/400\n",
            "91/91 [==============================] - 4s 44ms/step - loss: 0.0036 - accuracy: 0.9909 - val_loss: 0.0987 - val_accuracy: 0.8620\n",
            "Epoch 126/400\n",
            "91/91 [==============================] - 4s 44ms/step - loss: 0.0019 - accuracy: 0.9946 - val_loss: 0.1243 - val_accuracy: 0.8761\n",
            "Epoch 127/400\n",
            "91/91 [==============================] - 4s 44ms/step - loss: 0.0022 - accuracy: 0.9950 - val_loss: 0.1121 - val_accuracy: 0.8715\n",
            "Epoch 128/400\n",
            "91/91 [==============================] - 4s 44ms/step - loss: 0.0033 - accuracy: 0.9918 - val_loss: 0.1202 - val_accuracy: 0.8684\n",
            "Epoch 129/400\n",
            "91/91 [==============================] - 4s 44ms/step - loss: 0.0027 - accuracy: 0.9935 - val_loss: 0.1166 - val_accuracy: 0.8777\n",
            "Epoch 130/400\n",
            "91/91 [==============================] - 4s 44ms/step - loss: 0.0027 - accuracy: 0.9941 - val_loss: 0.1139 - val_accuracy: 0.8717\n",
            "Epoch 131/400\n",
            "91/91 [==============================] - 4s 44ms/step - loss: 0.0016 - accuracy: 0.9956 - val_loss: 0.1248 - val_accuracy: 0.8580\n",
            "Epoch 132/400\n",
            "91/91 [==============================] - 4s 44ms/step - loss: 0.0032 - accuracy: 0.9915 - val_loss: 0.1108 - val_accuracy: 0.8630\n",
            "Epoch 133/400\n",
            "91/91 [==============================] - 4s 44ms/step - loss: 0.0015 - accuracy: 0.9963 - val_loss: 0.1423 - val_accuracy: 0.8578\n",
            "Epoch 134/400\n",
            "91/91 [==============================] - 4s 44ms/step - loss: 0.0027 - accuracy: 0.9937 - val_loss: 0.1402 - val_accuracy: 0.8526\n",
            "Epoch 135/400\n",
            "91/91 [==============================] - 4s 44ms/step - loss: 0.0033 - accuracy: 0.9923 - val_loss: 0.1153 - val_accuracy: 0.8668\n",
            "Epoch 136/400\n",
            "91/91 [==============================] - 4s 44ms/step - loss: 0.0018 - accuracy: 0.9957 - val_loss: 0.1212 - val_accuracy: 0.8715\n",
            "Epoch 137/400\n",
            "91/91 [==============================] - 4s 44ms/step - loss: 0.0035 - accuracy: 0.9908 - val_loss: 0.0960 - val_accuracy: 0.8705\n",
            "Epoch 138/400\n",
            "91/91 [==============================] - 4s 44ms/step - loss: 0.0015 - accuracy: 0.9960 - val_loss: 0.1281 - val_accuracy: 0.8701\n",
            "Epoch 139/400\n",
            "91/91 [==============================] - 4s 44ms/step - loss: 0.0015 - accuracy: 0.9963 - val_loss: 0.1267 - val_accuracy: 0.8751\n",
            "Epoch 140/400\n",
            "91/91 [==============================] - 4s 44ms/step - loss: 0.0015 - accuracy: 0.9966 - val_loss: 0.1317 - val_accuracy: 0.8570\n",
            "Epoch 141/400\n",
            "91/91 [==============================] - 4s 44ms/step - loss: 0.0030 - accuracy: 0.9922 - val_loss: 0.0984 - val_accuracy: 0.8636\n",
            "Epoch 142/400\n",
            "91/91 [==============================] - 4s 44ms/step - loss: 0.0023 - accuracy: 0.9943 - val_loss: 0.1231 - val_accuracy: 0.8763\n",
            "Epoch 143/400\n",
            "91/91 [==============================] - 4s 44ms/step - loss: 0.0015 - accuracy: 0.9963 - val_loss: 0.1278 - val_accuracy: 0.8727\n",
            "Epoch 144/400\n",
            "91/91 [==============================] - 4s 44ms/step - loss: 0.0011 - accuracy: 0.9977 - val_loss: 0.1283 - val_accuracy: 0.8747\n",
            "Epoch 145/400\n",
            "91/91 [==============================] - 4s 43ms/step - loss: 0.0011 - accuracy: 0.9976 - val_loss: 0.1156 - val_accuracy: 0.8719\n",
            "Epoch 146/400\n",
            "91/91 [==============================] - 4s 44ms/step - loss: 9.6732e-04 - accuracy: 0.9982 - val_loss: 0.1173 - val_accuracy: 0.8785\n",
            "Epoch 147/400\n",
            "91/91 [==============================] - 4s 45ms/step - loss: 0.0011 - accuracy: 0.9980 - val_loss: 0.1083 - val_accuracy: 0.8795\n",
            "Epoch 148/400\n",
            "91/91 [==============================] - 4s 44ms/step - loss: 9.0342e-04 - accuracy: 0.9980 - val_loss: 0.1040 - val_accuracy: 0.8847\n",
            "Epoch 149/400\n",
            "91/91 [==============================] - 4s 44ms/step - loss: 7.4169e-04 - accuracy: 0.9984 - val_loss: 0.1134 - val_accuracy: 0.8857\n",
            "Epoch 150/400\n",
            "91/91 [==============================] - 4s 44ms/step - loss: 5.3526e-04 - accuracy: 0.9985 - val_loss: 0.1239 - val_accuracy: 0.8761\n",
            "Epoch 151/400\n",
            "91/91 [==============================] - 4s 44ms/step - loss: 5.8314e-04 - accuracy: 0.9986 - val_loss: 0.1236 - val_accuracy: 0.8817\n",
            "Epoch 152/400\n",
            "91/91 [==============================] - 4s 44ms/step - loss: 6.0040e-04 - accuracy: 0.9985 - val_loss: 0.1125 - val_accuracy: 0.8849\n",
            "Epoch 153/400\n",
            "91/91 [==============================] - 4s 44ms/step - loss: 7.5340e-04 - accuracy: 0.9985 - val_loss: 0.1053 - val_accuracy: 0.8811\n",
            "Epoch 154/400\n",
            "91/91 [==============================] - 4s 44ms/step - loss: 5.6703e-04 - accuracy: 0.9985 - val_loss: 0.1202 - val_accuracy: 0.8823\n",
            "Epoch 155/400\n",
            "91/91 [==============================] - 4s 43ms/step - loss: 0.0014 - accuracy: 0.9979 - val_loss: 0.0854 - val_accuracy: 0.8785\n",
            "Epoch 156/400\n",
            "91/91 [==============================] - 4s 44ms/step - loss: 5.5233e-04 - accuracy: 0.9985 - val_loss: 0.1158 - val_accuracy: 0.8805\n",
            "Epoch 157/400\n",
            "91/91 [==============================] - 4s 44ms/step - loss: 4.4848e-04 - accuracy: 0.9987 - val_loss: 0.1252 - val_accuracy: 0.8843\n",
            "Epoch 158/400\n",
            "91/91 [==============================] - 4s 44ms/step - loss: 8.4658e-04 - accuracy: 0.9985 - val_loss: 0.1166 - val_accuracy: 0.8662\n",
            "Epoch 159/400\n",
            "91/91 [==============================] - 4s 44ms/step - loss: 0.0011 - accuracy: 0.9978 - val_loss: 0.1112 - val_accuracy: 0.8809\n",
            "Epoch 160/400\n",
            "91/91 [==============================] - 4s 44ms/step - loss: 0.0010 - accuracy: 0.9973 - val_loss: 0.1186 - val_accuracy: 0.8749\n",
            "Epoch 161/400\n",
            "91/91 [==============================] - 4s 43ms/step - loss: 0.0048 - accuracy: 0.9867 - val_loss: 0.0709 - val_accuracy: 0.8445\n",
            "Epoch 162/400\n",
            "91/91 [==============================] - 4s 43ms/step - loss: 0.0077 - accuracy: 0.9811 - val_loss: 0.0844 - val_accuracy: 0.8666\n",
            "Epoch 163/400\n",
            "91/91 [==============================] - 4s 44ms/step - loss: 0.0056 - accuracy: 0.9848 - val_loss: 0.0947 - val_accuracy: 0.8618\n",
            "Epoch 164/400\n",
            "91/91 [==============================] - 4s 43ms/step - loss: 0.0037 - accuracy: 0.9903 - val_loss: 0.1208 - val_accuracy: 0.8574\n",
            "Epoch 165/400\n",
            "91/91 [==============================] - 4s 44ms/step - loss: 0.0021 - accuracy: 0.9943 - val_loss: 0.1392 - val_accuracy: 0.8560\n",
            "Epoch 166/400\n",
            "91/91 [==============================] - 4s 44ms/step - loss: 0.0024 - accuracy: 0.9949 - val_loss: 0.1136 - val_accuracy: 0.8644\n",
            "Epoch 167/400\n",
            "91/91 [==============================] - 4s 43ms/step - loss: 0.0027 - accuracy: 0.9929 - val_loss: 0.1144 - val_accuracy: 0.8725\n",
            "Epoch 168/400\n",
            "91/91 [==============================] - 4s 44ms/step - loss: 0.0016 - accuracy: 0.9962 - val_loss: 0.1306 - val_accuracy: 0.8666\n",
            "Epoch 169/400\n",
            "91/91 [==============================] - 4s 43ms/step - loss: 0.0026 - accuracy: 0.9943 - val_loss: 0.1135 - val_accuracy: 0.8622\n",
            "Epoch 170/400\n",
            "91/91 [==============================] - 4s 44ms/step - loss: 0.0023 - accuracy: 0.9947 - val_loss: 0.1027 - val_accuracy: 0.8705\n",
            "Epoch 171/400\n",
            "91/91 [==============================] - 4s 44ms/step - loss: 0.0012 - accuracy: 0.9965 - val_loss: 0.1290 - val_accuracy: 0.8763\n",
            "Epoch 172/400\n",
            "91/91 [==============================] - 4s 44ms/step - loss: 0.0012 - accuracy: 0.9971 - val_loss: 0.1439 - val_accuracy: 0.8731\n",
            "Epoch 173/400\n",
            "91/91 [==============================] - 4s 44ms/step - loss: 0.0016 - accuracy: 0.9960 - val_loss: 0.1224 - val_accuracy: 0.8717\n",
            "Epoch 174/400\n",
            "91/91 [==============================] - 4s 44ms/step - loss: 0.0012 - accuracy: 0.9979 - val_loss: 0.1326 - val_accuracy: 0.8763\n",
            "Epoch 175/400\n",
            "91/91 [==============================] - 4s 44ms/step - loss: 0.0011 - accuracy: 0.9977 - val_loss: 0.1133 - val_accuracy: 0.8769\n",
            "Epoch 176/400\n",
            "91/91 [==============================] - 4s 44ms/step - loss: 0.0012 - accuracy: 0.9984 - val_loss: 0.1208 - val_accuracy: 0.8697\n",
            "Epoch 177/400\n",
            "91/91 [==============================] - 4s 44ms/step - loss: 7.4232e-04 - accuracy: 0.9983 - val_loss: 0.1273 - val_accuracy: 0.8779\n",
            "Epoch 178/400\n",
            "91/91 [==============================] - 4s 44ms/step - loss: 7.9126e-04 - accuracy: 0.9985 - val_loss: 0.1090 - val_accuracy: 0.8757\n",
            "Epoch 179/400\n",
            "91/91 [==============================] - 4s 43ms/step - loss: 6.6128e-04 - accuracy: 0.9986 - val_loss: 0.1160 - val_accuracy: 0.8795\n",
            "Epoch 180/400\n",
            "91/91 [==============================] - 4s 43ms/step - loss: 5.8512e-04 - accuracy: 0.9985 - val_loss: 0.1175 - val_accuracy: 0.8837\n",
            "Epoch 181/400\n",
            "91/91 [==============================] - 4s 44ms/step - loss: 7.5416e-04 - accuracy: 0.9984 - val_loss: 0.1132 - val_accuracy: 0.8813\n",
            "Epoch 182/400\n",
            "91/91 [==============================] - 4s 44ms/step - loss: 5.4157e-04 - accuracy: 0.9989 - val_loss: 0.1347 - val_accuracy: 0.8741\n",
            "Epoch 183/400\n",
            "91/91 [==============================] - 4s 44ms/step - loss: 6.2494e-04 - accuracy: 0.9981 - val_loss: 0.1182 - val_accuracy: 0.8781\n",
            "Epoch 184/400\n",
            "91/91 [==============================] - 4s 44ms/step - loss: 8.3690e-04 - accuracy: 0.9984 - val_loss: 0.1161 - val_accuracy: 0.8759\n",
            "Epoch 185/400\n",
            "91/91 [==============================] - 4s 44ms/step - loss: 8.0044e-04 - accuracy: 0.9975 - val_loss: 0.1359 - val_accuracy: 0.8680\n",
            "Epoch 186/400\n",
            "91/91 [==============================] - 4s 43ms/step - loss: 4.6016e-04 - accuracy: 0.9991 - val_loss: 0.1592 - val_accuracy: 0.8654\n",
            "Epoch 187/400\n",
            "91/91 [==============================] - 4s 44ms/step - loss: 6.5656e-04 - accuracy: 0.9985 - val_loss: 0.1184 - val_accuracy: 0.8753\n",
            "Epoch 188/400\n",
            "91/91 [==============================] - 4s 44ms/step - loss: 6.7284e-04 - accuracy: 0.9985 - val_loss: 0.1628 - val_accuracy: 0.8596\n",
            "Epoch 189/400\n",
            "91/91 [==============================] - 4s 43ms/step - loss: 6.3727e-04 - accuracy: 0.9985 - val_loss: 0.1293 - val_accuracy: 0.8749\n",
            "Epoch 190/400\n",
            "91/91 [==============================] - 4s 43ms/step - loss: 4.5416e-04 - accuracy: 0.9987 - val_loss: 0.1187 - val_accuracy: 0.8787\n",
            "Epoch 191/400\n",
            "91/91 [==============================] - 4s 44ms/step - loss: 5.6095e-04 - accuracy: 0.9983 - val_loss: 0.1473 - val_accuracy: 0.8749\n",
            "Epoch 192/400\n",
            "91/91 [==============================] - 4s 44ms/step - loss: 8.2176e-04 - accuracy: 0.9983 - val_loss: 0.1183 - val_accuracy: 0.8759\n",
            "Epoch 193/400\n",
            "91/91 [==============================] - 4s 44ms/step - loss: 5.9960e-04 - accuracy: 0.9985 - val_loss: 0.1131 - val_accuracy: 0.8829\n",
            "Epoch 194/400\n",
            "91/91 [==============================] - 4s 44ms/step - loss: 6.1053e-04 - accuracy: 0.9986 - val_loss: 0.1198 - val_accuracy: 0.8811\n",
            "Epoch 195/400\n",
            "91/91 [==============================] - 4s 44ms/step - loss: 6.7401e-04 - accuracy: 0.9983 - val_loss: 0.1279 - val_accuracy: 0.8749\n",
            "Epoch 196/400\n",
            "91/91 [==============================] - 4s 44ms/step - loss: 0.0046 - accuracy: 0.9879 - val_loss: 0.0701 - val_accuracy: 0.8227\n",
            "Epoch 197/400\n",
            "91/91 [==============================] - 4s 44ms/step - loss: 0.0088 - accuracy: 0.9753 - val_loss: 0.0881 - val_accuracy: 0.8580\n",
            "Epoch 198/400\n",
            "91/91 [==============================] - 4s 44ms/step - loss: 0.0056 - accuracy: 0.9858 - val_loss: 0.1015 - val_accuracy: 0.8668\n",
            "Epoch 199/400\n",
            "91/91 [==============================] - 4s 44ms/step - loss: 0.0042 - accuracy: 0.9889 - val_loss: 0.1040 - val_accuracy: 0.8437\n",
            "Epoch 200/400\n",
            "91/91 [==============================] - 4s 44ms/step - loss: 0.0024 - accuracy: 0.9923 - val_loss: 0.1412 - val_accuracy: 0.8642\n",
            "Epoch 201/400\n",
            "91/91 [==============================] - 4s 44ms/step - loss: 0.0032 - accuracy: 0.9924 - val_loss: 0.1057 - val_accuracy: 0.8691\n",
            "Epoch 202/400\n",
            "91/91 [==============================] - 4s 44ms/step - loss: 0.0019 - accuracy: 0.9951 - val_loss: 0.1279 - val_accuracy: 0.8709\n",
            "Epoch 203/400\n",
            "91/91 [==============================] - 4s 44ms/step - loss: 0.0012 - accuracy: 0.9970 - val_loss: 0.1302 - val_accuracy: 0.8678\n",
            "Epoch 204/400\n",
            "91/91 [==============================] - 4s 44ms/step - loss: 0.0011 - accuracy: 0.9968 - val_loss: 0.1365 - val_accuracy: 0.8723\n",
            "Epoch 205/400\n",
            "91/91 [==============================] - 4s 44ms/step - loss: 0.0011 - accuracy: 0.9966 - val_loss: 0.1436 - val_accuracy: 0.8672\n",
            "Epoch 206/400\n",
            "91/91 [==============================] - 4s 44ms/step - loss: 0.0014 - accuracy: 0.9958 - val_loss: 0.1352 - val_accuracy: 0.8801\n",
            "Epoch 207/400\n",
            "91/91 [==============================] - 4s 44ms/step - loss: 0.0015 - accuracy: 0.9962 - val_loss: 0.1226 - val_accuracy: 0.8797\n",
            "Epoch 208/400\n",
            "91/91 [==============================] - 4s 44ms/step - loss: 0.0013 - accuracy: 0.9968 - val_loss: 0.1293 - val_accuracy: 0.8817\n",
            "Epoch 209/400\n",
            "91/91 [==============================] - 4s 44ms/step - loss: 7.7834e-04 - accuracy: 0.9978 - val_loss: 0.1326 - val_accuracy: 0.8833\n",
            "Epoch 210/400\n",
            "91/91 [==============================] - 4s 44ms/step - loss: 4.9317e-04 - accuracy: 0.9986 - val_loss: 0.1505 - val_accuracy: 0.8638\n",
            "Epoch 211/400\n",
            "91/91 [==============================] - 4s 44ms/step - loss: 7.6483e-04 - accuracy: 0.9983 - val_loss: 0.1270 - val_accuracy: 0.8857\n",
            "Epoch 212/400\n",
            "91/91 [==============================] - 4s 44ms/step - loss: 6.6539e-04 - accuracy: 0.9984 - val_loss: 0.1182 - val_accuracy: 0.8755\n",
            "Epoch 213/400\n",
            "91/91 [==============================] - 4s 44ms/step - loss: 4.8841e-04 - accuracy: 0.9987 - val_loss: 0.1246 - val_accuracy: 0.8847\n",
            "Epoch 214/400\n",
            "91/91 [==============================] - 4s 43ms/step - loss: 6.0975e-04 - accuracy: 0.9986 - val_loss: 0.1214 - val_accuracy: 0.8807\n",
            "Epoch 215/400\n",
            "91/91 [==============================] - 4s 44ms/step - loss: 5.2719e-04 - accuracy: 0.9985 - val_loss: 0.1111 - val_accuracy: 0.8839\n",
            "Epoch 216/400\n",
            "91/91 [==============================] - 4s 44ms/step - loss: 6.7992e-04 - accuracy: 0.9981 - val_loss: 0.1121 - val_accuracy: 0.8815\n",
            "Epoch 217/400\n",
            "91/91 [==============================] - 4s 44ms/step - loss: 6.3643e-04 - accuracy: 0.9981 - val_loss: 0.1238 - val_accuracy: 0.8789\n",
            "Epoch 218/400\n",
            "91/91 [==============================] - 4s 44ms/step - loss: 5.2465e-04 - accuracy: 0.9985 - val_loss: 0.1123 - val_accuracy: 0.8853\n",
            "Epoch 219/400\n",
            "91/91 [==============================] - 4s 44ms/step - loss: 4.4810e-04 - accuracy: 0.9986 - val_loss: 0.1275 - val_accuracy: 0.8761\n",
            "Epoch 220/400\n",
            "91/91 [==============================] - 4s 44ms/step - loss: 5.1901e-04 - accuracy: 0.9985 - val_loss: 0.1364 - val_accuracy: 0.8801\n",
            "Epoch 221/400\n",
            "91/91 [==============================] - 4s 44ms/step - loss: 3.5953e-04 - accuracy: 0.9989 - val_loss: 0.1261 - val_accuracy: 0.8801\n",
            "Epoch 222/400\n",
            "91/91 [==============================] - 4s 44ms/step - loss: 6.6092e-04 - accuracy: 0.9983 - val_loss: 0.1120 - val_accuracy: 0.8847\n",
            "Epoch 223/400\n",
            "91/91 [==============================] - 4s 44ms/step - loss: 5.0401e-04 - accuracy: 0.9985 - val_loss: 0.1133 - val_accuracy: 0.8853\n",
            "Epoch 224/400\n",
            "91/91 [==============================] - 4s 44ms/step - loss: 5.0113e-04 - accuracy: 0.9986 - val_loss: 0.1084 - val_accuracy: 0.8833\n",
            "Epoch 225/400\n",
            "91/91 [==============================] - 4s 44ms/step - loss: 5.7633e-04 - accuracy: 0.9985 - val_loss: 0.1132 - val_accuracy: 0.8845\n",
            "Epoch 226/400\n",
            "91/91 [==============================] - 4s 44ms/step - loss: 0.0014 - accuracy: 0.9970 - val_loss: 0.1190 - val_accuracy: 0.8654\n",
            "Epoch 227/400\n",
            "91/91 [==============================] - 4s 44ms/step - loss: 0.0063 - accuracy: 0.9836 - val_loss: 0.1341 - val_accuracy: 0.8411\n",
            "Epoch 228/400\n",
            "91/91 [==============================] - 4s 44ms/step - loss: 0.0061 - accuracy: 0.9833 - val_loss: 0.1029 - val_accuracy: 0.8405\n",
            "Epoch 229/400\n",
            "91/91 [==============================] - 4s 44ms/step - loss: 0.0036 - accuracy: 0.9918 - val_loss: 0.1141 - val_accuracy: 0.8753\n",
            "Epoch 230/400\n",
            "91/91 [==============================] - 4s 44ms/step - loss: 0.0021 - accuracy: 0.9947 - val_loss: 0.1129 - val_accuracy: 0.8755\n",
            "Epoch 231/400\n",
            "91/91 [==============================] - 4s 44ms/step - loss: 0.0012 - accuracy: 0.9970 - val_loss: 0.1321 - val_accuracy: 0.8783\n",
            "Epoch 232/400\n",
            "91/91 [==============================] - 4s 44ms/step - loss: 0.0022 - accuracy: 0.9948 - val_loss: 0.1101 - val_accuracy: 0.8552\n",
            "Epoch 233/400\n",
            "91/91 [==============================] - 4s 44ms/step - loss: 0.0028 - accuracy: 0.9930 - val_loss: 0.1138 - val_accuracy: 0.8783\n",
            "Epoch 234/400\n",
            "91/91 [==============================] - 4s 44ms/step - loss: 0.0017 - accuracy: 0.9961 - val_loss: 0.1176 - val_accuracy: 0.8739\n",
            "Epoch 235/400\n",
            "91/91 [==============================] - 4s 44ms/step - loss: 0.0013 - accuracy: 0.9973 - val_loss: 0.1253 - val_accuracy: 0.8825\n",
            "Epoch 236/400\n",
            "91/91 [==============================] - 4s 44ms/step - loss: 8.1555e-04 - accuracy: 0.9980 - val_loss: 0.1367 - val_accuracy: 0.8795\n",
            "Epoch 237/400\n",
            "91/91 [==============================] - 4s 44ms/step - loss: 7.5464e-04 - accuracy: 0.9982 - val_loss: 0.1302 - val_accuracy: 0.8797\n",
            "Epoch 238/400\n",
            "91/91 [==============================] - 4s 44ms/step - loss: 4.9199e-04 - accuracy: 0.9985 - val_loss: 0.1376 - val_accuracy: 0.8829\n",
            "Epoch 239/400\n",
            "91/91 [==============================] - 4s 44ms/step - loss: 5.2419e-04 - accuracy: 0.9987 - val_loss: 0.1307 - val_accuracy: 0.8847\n",
            "Epoch 240/400\n",
            "91/91 [==============================] - 4s 44ms/step - loss: 5.0475e-04 - accuracy: 0.9987 - val_loss: 0.1237 - val_accuracy: 0.8845\n",
            "Epoch 241/400\n",
            "91/91 [==============================] - 4s 44ms/step - loss: 4.5243e-04 - accuracy: 0.9987 - val_loss: 0.1239 - val_accuracy: 0.8849\n",
            "Epoch 242/400\n",
            "91/91 [==============================] - 4s 44ms/step - loss: 6.5491e-04 - accuracy: 0.9981 - val_loss: 0.1220 - val_accuracy: 0.8785\n",
            "Epoch 243/400\n",
            "91/91 [==============================] - 4s 44ms/step - loss: 5.8840e-04 - accuracy: 0.9985 - val_loss: 0.1191 - val_accuracy: 0.8821\n",
            "Epoch 244/400\n",
            "91/91 [==============================] - 4s 44ms/step - loss: 5.3462e-04 - accuracy: 0.9984 - val_loss: 0.1193 - val_accuracy: 0.8795\n",
            "Epoch 245/400\n",
            "91/91 [==============================] - 4s 44ms/step - loss: 5.5928e-04 - accuracy: 0.9987 - val_loss: 0.1254 - val_accuracy: 0.8785\n",
            "Epoch 246/400\n",
            "91/91 [==============================] - 4s 44ms/step - loss: 4.1042e-04 - accuracy: 0.9987 - val_loss: 0.1193 - val_accuracy: 0.8823\n",
            "Epoch 247/400\n",
            "91/91 [==============================] - 4s 44ms/step - loss: 5.5383e-04 - accuracy: 0.9986 - val_loss: 0.1204 - val_accuracy: 0.8839\n",
            "Epoch 248/400\n",
            "91/91 [==============================] - 4s 44ms/step - loss: 5.4970e-04 - accuracy: 0.9984 - val_loss: 0.1140 - val_accuracy: 0.8813\n",
            "Epoch 249/400\n",
            "91/91 [==============================] - 4s 44ms/step - loss: 5.0322e-04 - accuracy: 0.9985 - val_loss: 0.1262 - val_accuracy: 0.8733\n",
            "Epoch 250/400\n",
            "91/91 [==============================] - 4s 44ms/step - loss: 8.3014e-04 - accuracy: 0.9985 - val_loss: 0.1021 - val_accuracy: 0.8825\n",
            "Epoch 251/400\n",
            "91/91 [==============================] - 4s 44ms/step - loss: 6.7544e-04 - accuracy: 0.9985 - val_loss: 0.1146 - val_accuracy: 0.8741\n",
            "Epoch 252/400\n",
            "91/91 [==============================] - 4s 44ms/step - loss: 5.2105e-04 - accuracy: 0.9989 - val_loss: 0.1156 - val_accuracy: 0.8815\n",
            "Epoch 253/400\n",
            "91/91 [==============================] - 4s 44ms/step - loss: 4.7247e-04 - accuracy: 0.9982 - val_loss: 0.1075 - val_accuracy: 0.8833\n",
            "Epoch 254/400\n",
            "91/91 [==============================] - 4s 44ms/step - loss: 6.0643e-04 - accuracy: 0.9983 - val_loss: 0.1091 - val_accuracy: 0.8849\n",
            "Epoch 255/400\n",
            "91/91 [==============================] - 4s 44ms/step - loss: 6.3430e-04 - accuracy: 0.9985 - val_loss: 0.1105 - val_accuracy: 0.8801\n",
            "Epoch 256/400\n",
            "91/91 [==============================] - 4s 44ms/step - loss: 4.6384e-04 - accuracy: 0.9986 - val_loss: 0.1170 - val_accuracy: 0.8823\n",
            "Epoch 257/400\n",
            "91/91 [==============================] - 4s 44ms/step - loss: 5.0440e-04 - accuracy: 0.9991 - val_loss: 0.1182 - val_accuracy: 0.8799\n",
            "Epoch 258/400\n",
            "91/91 [==============================] - 4s 44ms/step - loss: 4.5177e-04 - accuracy: 0.9987 - val_loss: 0.1266 - val_accuracy: 0.8815\n",
            "Epoch 259/400\n",
            "91/91 [==============================] - 4s 45ms/step - loss: 7.9792e-04 - accuracy: 0.9985 - val_loss: 0.1266 - val_accuracy: 0.8699\n",
            "Epoch 260/400\n",
            "91/91 [==============================] - 4s 45ms/step - loss: 0.0040 - accuracy: 0.9886 - val_loss: 0.0762 - val_accuracy: 0.8431\n",
            "Epoch 261/400\n",
            "91/91 [==============================] - 4s 45ms/step - loss: 0.0057 - accuracy: 0.9837 - val_loss: 0.1001 - val_accuracy: 0.8791\n",
            "Epoch 262/400\n",
            "91/91 [==============================] - 4s 44ms/step - loss: 0.0038 - accuracy: 0.9900 - val_loss: 0.1006 - val_accuracy: 0.8664\n",
            "Epoch 263/400\n",
            "91/91 [==============================] - 4s 44ms/step - loss: 0.0019 - accuracy: 0.9952 - val_loss: 0.1243 - val_accuracy: 0.8763\n",
            "Epoch 264/400\n",
            "91/91 [==============================] - 4s 45ms/step - loss: 0.0017 - accuracy: 0.9966 - val_loss: 0.1276 - val_accuracy: 0.8761\n",
            "Epoch 265/400\n",
            "91/91 [==============================] - 4s 44ms/step - loss: 6.7203e-04 - accuracy: 0.9978 - val_loss: 0.1403 - val_accuracy: 0.8801\n",
            "Epoch 266/400\n",
            "91/91 [==============================] - 4s 45ms/step - loss: 4.4399e-04 - accuracy: 0.9988 - val_loss: 0.1537 - val_accuracy: 0.8773\n",
            "Epoch 267/400\n",
            "91/91 [==============================] - 4s 44ms/step - loss: 0.0014 - accuracy: 0.9965 - val_loss: 0.1375 - val_accuracy: 0.8727\n",
            "Epoch 268/400\n",
            "91/91 [==============================] - 4s 45ms/step - loss: 0.0027 - accuracy: 0.9935 - val_loss: 0.1182 - val_accuracy: 0.8757\n",
            "Epoch 269/400\n",
            "91/91 [==============================] - 4s 44ms/step - loss: 0.0015 - accuracy: 0.9961 - val_loss: 0.1326 - val_accuracy: 0.8759\n",
            "Epoch 270/400\n",
            "91/91 [==============================] - 4s 45ms/step - loss: 6.6995e-04 - accuracy: 0.9986 - val_loss: 0.1494 - val_accuracy: 0.8827\n",
            "Epoch 271/400\n",
            "91/91 [==============================] - 4s 44ms/step - loss: 5.7302e-04 - accuracy: 0.9983 - val_loss: 0.1450 - val_accuracy: 0.8779\n",
            "Epoch 272/400\n",
            "91/91 [==============================] - 4s 45ms/step - loss: 3.7801e-04 - accuracy: 0.9986 - val_loss: 0.1447 - val_accuracy: 0.8815\n",
            "Epoch 273/400\n",
            "91/91 [==============================] - 4s 44ms/step - loss: 4.4693e-04 - accuracy: 0.9985 - val_loss: 0.1465 - val_accuracy: 0.8849\n",
            "Epoch 274/400\n",
            "91/91 [==============================] - 4s 44ms/step - loss: 5.2415e-04 - accuracy: 0.9982 - val_loss: 0.1395 - val_accuracy: 0.8849\n",
            "Epoch 275/400\n",
            "91/91 [==============================] - 4s 45ms/step - loss: 5.5971e-04 - accuracy: 0.9983 - val_loss: 0.1237 - val_accuracy: 0.8777\n",
            "Epoch 276/400\n",
            "91/91 [==============================] - 4s 45ms/step - loss: 3.9030e-04 - accuracy: 0.9985 - val_loss: 0.1379 - val_accuracy: 0.8829\n",
            "Epoch 277/400\n",
            "91/91 [==============================] - 4s 45ms/step - loss: 6.3587e-04 - accuracy: 0.9985 - val_loss: 0.1262 - val_accuracy: 0.8797\n",
            "Epoch 278/400\n",
            "91/91 [==============================] - 4s 44ms/step - loss: 5.5808e-04 - accuracy: 0.9988 - val_loss: 0.1288 - val_accuracy: 0.8795\n",
            "Epoch 279/400\n",
            "91/91 [==============================] - 4s 44ms/step - loss: 4.7296e-04 - accuracy: 0.9985 - val_loss: 0.1311 - val_accuracy: 0.8791\n",
            "Epoch 280/400\n",
            "91/91 [==============================] - 4s 45ms/step - loss: 3.8571e-04 - accuracy: 0.9987 - val_loss: 0.1329 - val_accuracy: 0.8815\n",
            "Epoch 281/400\n",
            "91/91 [==============================] - 4s 44ms/step - loss: 4.3214e-04 - accuracy: 0.9987 - val_loss: 0.1357 - val_accuracy: 0.8815\n",
            "Epoch 282/400\n",
            "91/91 [==============================] - 4s 45ms/step - loss: 5.7978e-04 - accuracy: 0.9983 - val_loss: 0.1230 - val_accuracy: 0.8795\n",
            "Epoch 283/400\n",
            "91/91 [==============================] - 4s 45ms/step - loss: 5.5672e-04 - accuracy: 0.9984 - val_loss: 0.1213 - val_accuracy: 0.8801\n",
            "Epoch 284/400\n",
            "91/91 [==============================] - 4s 44ms/step - loss: 5.2441e-04 - accuracy: 0.9986 - val_loss: 0.1226 - val_accuracy: 0.8747\n",
            "Epoch 285/400\n",
            "91/91 [==============================] - 4s 45ms/step - loss: 7.4684e-04 - accuracy: 0.9984 - val_loss: 0.1090 - val_accuracy: 0.8797\n",
            "Epoch 286/400\n",
            "91/91 [==============================] - 4s 45ms/step - loss: 4.8062e-04 - accuracy: 0.9985 - val_loss: 0.1229 - val_accuracy: 0.8833\n",
            "Epoch 287/400\n",
            "91/91 [==============================] - 4s 45ms/step - loss: 4.5130e-04 - accuracy: 0.9983 - val_loss: 0.1235 - val_accuracy: 0.8839\n",
            "Epoch 288/400\n",
            "91/91 [==============================] - 4s 45ms/step - loss: 4.6278e-04 - accuracy: 0.9986 - val_loss: 0.1301 - val_accuracy: 0.8837\n",
            "Epoch 289/400\n",
            "91/91 [==============================] - 4s 46ms/step - loss: 5.9923e-04 - accuracy: 0.9987 - val_loss: 0.1186 - val_accuracy: 0.8793\n",
            "Epoch 290/400\n",
            "91/91 [==============================] - 4s 45ms/step - loss: 6.0799e-04 - accuracy: 0.9986 - val_loss: 0.1240 - val_accuracy: 0.8743\n",
            "Epoch 291/400\n",
            "91/91 [==============================] - 4s 45ms/step - loss: 5.1482e-04 - accuracy: 0.9985 - val_loss: 0.1230 - val_accuracy: 0.8819\n",
            "Epoch 292/400\n",
            "91/91 [==============================] - 4s 44ms/step - loss: 4.9219e-04 - accuracy: 0.9984 - val_loss: 0.1223 - val_accuracy: 0.8837\n",
            "Epoch 293/400\n",
            "91/91 [==============================] - 4s 45ms/step - loss: 6.6811e-04 - accuracy: 0.9983 - val_loss: 0.1197 - val_accuracy: 0.8769\n",
            "Epoch 294/400\n",
            "91/91 [==============================] - 4s 45ms/step - loss: 5.3415e-04 - accuracy: 0.9985 - val_loss: 0.1266 - val_accuracy: 0.8799\n",
            "Epoch 295/400\n",
            "91/91 [==============================] - 4s 44ms/step - loss: 5.5006e-04 - accuracy: 0.9985 - val_loss: 0.1245 - val_accuracy: 0.8805\n",
            "Epoch 296/400\n",
            "91/91 [==============================] - 4s 44ms/step - loss: 4.1701e-04 - accuracy: 0.9986 - val_loss: 0.1227 - val_accuracy: 0.8817\n",
            "Epoch 297/400\n",
            "91/91 [==============================] - 4s 45ms/step - loss: 5.1433e-04 - accuracy: 0.9987 - val_loss: 0.1258 - val_accuracy: 0.8803\n",
            "Epoch 298/400\n",
            "91/91 [==============================] - 4s 45ms/step - loss: 5.3183e-04 - accuracy: 0.9984 - val_loss: 0.1221 - val_accuracy: 0.8823\n",
            "Epoch 299/400\n",
            "91/91 [==============================] - 4s 45ms/step - loss: 4.5438e-04 - accuracy: 0.9983 - val_loss: 0.1191 - val_accuracy: 0.8797\n",
            "Epoch 300/400\n",
            "91/91 [==============================] - 4s 45ms/step - loss: 4.4293e-04 - accuracy: 0.9987 - val_loss: 0.1471 - val_accuracy: 0.8678\n",
            "Epoch 301/400\n",
            "91/91 [==============================] - 4s 44ms/step - loss: 3.5312e-04 - accuracy: 0.9991 - val_loss: 0.1341 - val_accuracy: 0.8803\n",
            "Epoch 302/400\n",
            "91/91 [==============================] - 4s 45ms/step - loss: 3.4596e-04 - accuracy: 0.9988 - val_loss: 0.1252 - val_accuracy: 0.8847\n",
            "Epoch 303/400\n",
            "91/91 [==============================] - 4s 45ms/step - loss: 4.5827e-04 - accuracy: 0.9989 - val_loss: 0.1501 - val_accuracy: 0.8699\n",
            "Epoch 304/400\n",
            "91/91 [==============================] - 4s 45ms/step - loss: 6.5525e-04 - accuracy: 0.9985 - val_loss: 0.1138 - val_accuracy: 0.8821\n",
            "Epoch 305/400\n",
            "91/91 [==============================] - 4s 44ms/step - loss: 0.0039 - accuracy: 0.9916 - val_loss: 0.0753 - val_accuracy: 0.8373\n",
            "Epoch 306/400\n",
            "91/91 [==============================] - 4s 45ms/step - loss: 0.0081 - accuracy: 0.9775 - val_loss: 0.0886 - val_accuracy: 0.8502\n",
            "Epoch 307/400\n",
            "91/91 [==============================] - 4s 45ms/step - loss: 0.0039 - accuracy: 0.9909 - val_loss: 0.1044 - val_accuracy: 0.8586\n",
            "Epoch 308/400\n",
            "91/91 [==============================] - 4s 44ms/step - loss: 0.0020 - accuracy: 0.9947 - val_loss: 0.1078 - val_accuracy: 0.8785\n",
            "Epoch 309/400\n",
            "91/91 [==============================] - 4s 45ms/step - loss: 0.0036 - accuracy: 0.9906 - val_loss: 0.0995 - val_accuracy: 0.8773\n",
            "Epoch 310/400\n",
            "91/91 [==============================] - 4s 45ms/step - loss: 0.0013 - accuracy: 0.9970 - val_loss: 0.1199 - val_accuracy: 0.8833\n",
            "Epoch 311/400\n",
            "91/91 [==============================] - 4s 44ms/step - loss: 6.2195e-04 - accuracy: 0.9981 - val_loss: 0.1310 - val_accuracy: 0.8811\n",
            "Epoch 312/400\n",
            "91/91 [==============================] - 4s 45ms/step - loss: 4.4365e-04 - accuracy: 0.9985 - val_loss: 0.1385 - val_accuracy: 0.8829\n",
            "Epoch 313/400\n",
            "91/91 [==============================] - 4s 44ms/step - loss: 4.7858e-04 - accuracy: 0.9987 - val_loss: 0.1397 - val_accuracy: 0.8805\n",
            "Epoch 314/400\n",
            "91/91 [==============================] - 4s 44ms/step - loss: 6.0142e-04 - accuracy: 0.9984 - val_loss: 0.1281 - val_accuracy: 0.8815\n",
            "Epoch 315/400\n",
            "91/91 [==============================] - 4s 44ms/step - loss: 5.4355e-04 - accuracy: 0.9983 - val_loss: 0.1264 - val_accuracy: 0.8831\n",
            "Epoch 316/400\n",
            "91/91 [==============================] - 4s 45ms/step - loss: 5.8458e-04 - accuracy: 0.9984 - val_loss: 0.1283 - val_accuracy: 0.8817\n",
            "Epoch 317/400\n",
            "91/91 [==============================] - 4s 45ms/step - loss: 8.4039e-04 - accuracy: 0.9985 - val_loss: 0.1119 - val_accuracy: 0.8799\n",
            "Epoch 318/400\n",
            "91/91 [==============================] - 4s 45ms/step - loss: 4.7064e-04 - accuracy: 0.9982 - val_loss: 0.1193 - val_accuracy: 0.8829\n",
            "Epoch 319/400\n",
            "91/91 [==============================] - 4s 45ms/step - loss: 5.5009e-04 - accuracy: 0.9984 - val_loss: 0.1198 - val_accuracy: 0.8795\n",
            "Epoch 320/400\n",
            "91/91 [==============================] - 4s 45ms/step - loss: 5.3525e-04 - accuracy: 0.9982 - val_loss: 0.1213 - val_accuracy: 0.8817\n",
            "Epoch 321/400\n",
            "91/91 [==============================] - 4s 45ms/step - loss: 5.5091e-04 - accuracy: 0.9985 - val_loss: 0.1194 - val_accuracy: 0.8809\n",
            "Epoch 322/400\n",
            "91/91 [==============================] - 4s 45ms/step - loss: 4.1237e-04 - accuracy: 0.9985 - val_loss: 0.1225 - val_accuracy: 0.8811\n",
            "Epoch 323/400\n",
            "91/91 [==============================] - 4s 45ms/step - loss: 4.4325e-04 - accuracy: 0.9985 - val_loss: 0.1211 - val_accuracy: 0.8809\n",
            "Epoch 324/400\n",
            "91/91 [==============================] - 4s 45ms/step - loss: 4.0954e-04 - accuracy: 0.9983 - val_loss: 0.1242 - val_accuracy: 0.8841\n",
            "Epoch 325/400\n",
            "91/91 [==============================] - 4s 45ms/step - loss: 5.9781e-04 - accuracy: 0.9983 - val_loss: 0.1102 - val_accuracy: 0.8781\n",
            "Epoch 326/400\n",
            "91/91 [==============================] - 4s 45ms/step - loss: 3.6445e-04 - accuracy: 0.9986 - val_loss: 0.1236 - val_accuracy: 0.8813\n",
            "Epoch 327/400\n",
            "91/91 [==============================] - 4s 45ms/step - loss: 4.9776e-04 - accuracy: 0.9985 - val_loss: 0.1203 - val_accuracy: 0.8815\n",
            "Epoch 328/400\n",
            "91/91 [==============================] - 4s 44ms/step - loss: 4.9225e-04 - accuracy: 0.9989 - val_loss: 0.1209 - val_accuracy: 0.8825\n",
            "Epoch 329/400\n",
            "91/91 [==============================] - 4s 44ms/step - loss: 4.5098e-04 - accuracy: 0.9982 - val_loss: 0.1208 - val_accuracy: 0.8847\n",
            "Epoch 330/400\n",
            "91/91 [==============================] - 4s 45ms/step - loss: 7.1801e-04 - accuracy: 0.9986 - val_loss: 0.1118 - val_accuracy: 0.8831\n",
            "Epoch 331/400\n",
            "91/91 [==============================] - 4s 45ms/step - loss: 5.2925e-04 - accuracy: 0.9987 - val_loss: 0.1248 - val_accuracy: 0.8777\n",
            "Epoch 332/400\n",
            "91/91 [==============================] - 4s 45ms/step - loss: 4.5824e-04 - accuracy: 0.9983 - val_loss: 0.1266 - val_accuracy: 0.8745\n",
            "Epoch 333/400\n",
            "91/91 [==============================] - 4s 44ms/step - loss: 5.8668e-04 - accuracy: 0.9984 - val_loss: 0.1268 - val_accuracy: 0.8823\n",
            "Epoch 334/400\n",
            "91/91 [==============================] - 4s 44ms/step - loss: 5.0512e-04 - accuracy: 0.9988 - val_loss: 0.1160 - val_accuracy: 0.8777\n",
            "Epoch 335/400\n",
            "91/91 [==============================] - 4s 45ms/step - loss: 5.3715e-04 - accuracy: 0.9985 - val_loss: 0.1347 - val_accuracy: 0.8797\n",
            "Epoch 336/400\n",
            "91/91 [==============================] - 4s 45ms/step - loss: 5.2747e-04 - accuracy: 0.9985 - val_loss: 0.1364 - val_accuracy: 0.8753\n",
            "Epoch 337/400\n",
            "91/91 [==============================] - 4s 44ms/step - loss: 0.0012 - accuracy: 0.9969 - val_loss: 0.1233 - val_accuracy: 0.8703\n",
            "Epoch 338/400\n",
            "91/91 [==============================] - 4s 44ms/step - loss: 0.0064 - accuracy: 0.9846 - val_loss: 0.0741 - val_accuracy: 0.8634\n",
            "Epoch 339/400\n",
            "91/91 [==============================] - 4s 45ms/step - loss: 0.0038 - accuracy: 0.9911 - val_loss: 0.1029 - val_accuracy: 0.8759\n",
            "Epoch 340/400\n",
            "91/91 [==============================] - 4s 45ms/step - loss: 0.0020 - accuracy: 0.9948 - val_loss: 0.1234 - val_accuracy: 0.8703\n",
            "Epoch 341/400\n",
            "91/91 [==============================] - 4s 45ms/step - loss: 0.0016 - accuracy: 0.9966 - val_loss: 0.1066 - val_accuracy: 0.8602\n",
            "Epoch 342/400\n",
            "91/91 [==============================] - 4s 44ms/step - loss: 0.0013 - accuracy: 0.9966 - val_loss: 0.1551 - val_accuracy: 0.8713\n",
            "Epoch 343/400\n",
            "91/91 [==============================] - 4s 45ms/step - loss: 0.0014 - accuracy: 0.9957 - val_loss: 0.1514 - val_accuracy: 0.8717\n",
            "Epoch 344/400\n",
            "91/91 [==============================] - 4s 45ms/step - loss: 0.0021 - accuracy: 0.9940 - val_loss: 0.1276 - val_accuracy: 0.8676\n",
            "Epoch 345/400\n",
            "91/91 [==============================] - 4s 45ms/step - loss: 9.7445e-04 - accuracy: 0.9973 - val_loss: 0.1413 - val_accuracy: 0.8678\n",
            "Epoch 346/400\n",
            "91/91 [==============================] - 4s 46ms/step - loss: 0.0012 - accuracy: 0.9967 - val_loss: 0.1325 - val_accuracy: 0.8668\n",
            "Epoch 347/400\n",
            "91/91 [==============================] - 4s 45ms/step - loss: 9.9133e-04 - accuracy: 0.9973 - val_loss: 0.1452 - val_accuracy: 0.8787\n",
            "Epoch 348/400\n",
            "91/91 [==============================] - 4s 45ms/step - loss: 7.4722e-04 - accuracy: 0.9979 - val_loss: 0.1453 - val_accuracy: 0.8769\n",
            "Epoch 349/400\n",
            "91/91 [==============================] - 4s 45ms/step - loss: 7.1073e-04 - accuracy: 0.9980 - val_loss: 0.1491 - val_accuracy: 0.8789\n",
            "Epoch 350/400\n",
            "91/91 [==============================] - 4s 45ms/step - loss: 5.1440e-04 - accuracy: 0.9985 - val_loss: 0.1510 - val_accuracy: 0.8839\n",
            "Epoch 351/400\n",
            "91/91 [==============================] - 4s 45ms/step - loss: 3.8298e-04 - accuracy: 0.9989 - val_loss: 0.1519 - val_accuracy: 0.8831\n",
            "Epoch 352/400\n",
            "91/91 [==============================] - 4s 45ms/step - loss: 8.6836e-04 - accuracy: 0.9977 - val_loss: 0.1518 - val_accuracy: 0.8688\n",
            "Epoch 353/400\n",
            "91/91 [==============================] - 4s 44ms/step - loss: 5.6384e-04 - accuracy: 0.9984 - val_loss: 0.1535 - val_accuracy: 0.8769\n",
            "Epoch 354/400\n",
            "91/91 [==============================] - 4s 45ms/step - loss: 3.0123e-04 - accuracy: 0.9991 - val_loss: 0.1610 - val_accuracy: 0.8795\n",
            "Epoch 355/400\n",
            "91/91 [==============================] - 4s 45ms/step - loss: 3.7624e-04 - accuracy: 0.9990 - val_loss: 0.1590 - val_accuracy: 0.8815\n",
            "Epoch 356/400\n",
            "91/91 [==============================] - 4s 45ms/step - loss: 6.5439e-04 - accuracy: 0.9985 - val_loss: 0.1355 - val_accuracy: 0.8815\n",
            "Epoch 357/400\n",
            "91/91 [==============================] - 4s 45ms/step - loss: 7.6146e-04 - accuracy: 0.9984 - val_loss: 0.1331 - val_accuracy: 0.8755\n",
            "Epoch 358/400\n",
            "91/91 [==============================] - 4s 45ms/step - loss: 4.5503e-04 - accuracy: 0.9987 - val_loss: 0.1369 - val_accuracy: 0.8829\n",
            "Epoch 359/400\n",
            "91/91 [==============================] - 4s 44ms/step - loss: 3.7671e-04 - accuracy: 0.9986 - val_loss: 0.1442 - val_accuracy: 0.8815\n",
            "Epoch 360/400\n",
            "91/91 [==============================] - 4s 46ms/step - loss: 4.3327e-04 - accuracy: 0.9987 - val_loss: 0.1367 - val_accuracy: 0.8819\n",
            "Epoch 361/400\n",
            "91/91 [==============================] - 4s 45ms/step - loss: 3.7743e-04 - accuracy: 0.9987 - val_loss: 0.1344 - val_accuracy: 0.8803\n",
            "Epoch 362/400\n",
            "91/91 [==============================] - 4s 45ms/step - loss: 4.1085e-04 - accuracy: 0.9985 - val_loss: 0.1368 - val_accuracy: 0.8789\n",
            "Epoch 363/400\n",
            "91/91 [==============================] - 4s 44ms/step - loss: 4.2933e-04 - accuracy: 0.9985 - val_loss: 0.1349 - val_accuracy: 0.8823\n",
            "Epoch 364/400\n",
            "91/91 [==============================] - 4s 45ms/step - loss: 3.2567e-04 - accuracy: 0.9987 - val_loss: 0.1383 - val_accuracy: 0.8813\n",
            "Epoch 365/400\n",
            "91/91 [==============================] - 4s 45ms/step - loss: 3.7189e-04 - accuracy: 0.9984 - val_loss: 0.1402 - val_accuracy: 0.8803\n",
            "Epoch 366/400\n",
            "91/91 [==============================] - 4s 45ms/step - loss: 3.8484e-04 - accuracy: 0.9985 - val_loss: 0.1381 - val_accuracy: 0.8821\n",
            "Epoch 367/400\n",
            "91/91 [==============================] - 4s 45ms/step - loss: 4.7243e-04 - accuracy: 0.9987 - val_loss: 0.1212 - val_accuracy: 0.8735\n",
            "Epoch 368/400\n",
            "91/91 [==============================] - 4s 45ms/step - loss: 5.7329e-04 - accuracy: 0.9987 - val_loss: 0.1400 - val_accuracy: 0.8745\n",
            "Epoch 369/400\n",
            "91/91 [==============================] - 4s 45ms/step - loss: 6.6146e-04 - accuracy: 0.9983 - val_loss: 0.1275 - val_accuracy: 0.8775\n",
            "Epoch 370/400\n",
            "91/91 [==============================] - 4s 45ms/step - loss: 4.8251e-04 - accuracy: 0.9986 - val_loss: 0.1210 - val_accuracy: 0.8863\n",
            "Epoch 371/400\n",
            "91/91 [==============================] - 4s 45ms/step - loss: 4.3790e-04 - accuracy: 0.9984 - val_loss: 0.1216 - val_accuracy: 0.8837\n",
            "Epoch 372/400\n",
            "91/91 [==============================] - 4s 45ms/step - loss: 3.9143e-04 - accuracy: 0.9986 - val_loss: 0.1302 - val_accuracy: 0.8815\n",
            "Epoch 373/400\n",
            "91/91 [==============================] - 4s 45ms/step - loss: 4.6841e-04 - accuracy: 0.9985 - val_loss: 0.1360 - val_accuracy: 0.8811\n",
            "Epoch 374/400\n",
            "91/91 [==============================] - 4s 45ms/step - loss: 7.2216e-04 - accuracy: 0.9981 - val_loss: 0.1141 - val_accuracy: 0.8837\n",
            "Epoch 375/400\n",
            "91/91 [==============================] - 4s 45ms/step - loss: 3.5439e-04 - accuracy: 0.9985 - val_loss: 0.1313 - val_accuracy: 0.8861\n",
            "Epoch 376/400\n",
            "91/91 [==============================] - 4s 45ms/step - loss: 4.0369e-04 - accuracy: 0.9988 - val_loss: 0.1304 - val_accuracy: 0.8839\n",
            "Epoch 377/400\n",
            "91/91 [==============================] - 4s 45ms/step - loss: 3.9848e-04 - accuracy: 0.9987 - val_loss: 0.1318 - val_accuracy: 0.8791\n",
            "Epoch 378/400\n",
            "91/91 [==============================] - 4s 45ms/step - loss: 3.5198e-04 - accuracy: 0.9990 - val_loss: 0.1349 - val_accuracy: 0.8853\n",
            "Epoch 379/400\n",
            "91/91 [==============================] - 4s 45ms/step - loss: 5.7644e-04 - accuracy: 0.9985 - val_loss: 0.1221 - val_accuracy: 0.8811\n",
            "Epoch 380/400\n",
            "91/91 [==============================] - 4s 46ms/step - loss: 4.2950e-04 - accuracy: 0.9989 - val_loss: 0.1257 - val_accuracy: 0.8831\n",
            "Epoch 381/400\n",
            "91/91 [==============================] - 4s 45ms/step - loss: 4.1581e-04 - accuracy: 0.9988 - val_loss: 0.1326 - val_accuracy: 0.8841\n",
            "Epoch 382/400\n",
            "91/91 [==============================] - 4s 45ms/step - loss: 0.0020 - accuracy: 0.9951 - val_loss: 0.1012 - val_accuracy: 0.7883\n",
            "Epoch 383/400\n",
            "91/91 [==============================] - 4s 45ms/step - loss: 0.0072 - accuracy: 0.9809 - val_loss: 0.0932 - val_accuracy: 0.8598\n",
            "Epoch 384/400\n",
            "91/91 [==============================] - 4s 45ms/step - loss: 0.0023 - accuracy: 0.9944 - val_loss: 0.1217 - val_accuracy: 0.8729\n",
            "Epoch 385/400\n",
            "91/91 [==============================] - 4s 45ms/step - loss: 0.0024 - accuracy: 0.9942 - val_loss: 0.1221 - val_accuracy: 0.8686\n",
            "Epoch 386/400\n",
            "91/91 [==============================] - 4s 44ms/step - loss: 7.8448e-04 - accuracy: 0.9976 - val_loss: 0.1378 - val_accuracy: 0.8763\n",
            "Epoch 387/400\n",
            "91/91 [==============================] - 4s 46ms/step - loss: 3.8379e-04 - accuracy: 0.9987 - val_loss: 0.1515 - val_accuracy: 0.8805\n",
            "Epoch 388/400\n",
            "91/91 [==============================] - 4s 45ms/step - loss: 4.4691e-04 - accuracy: 0.9988 - val_loss: 0.1487 - val_accuracy: 0.8803\n",
            "Epoch 389/400\n",
            "91/91 [==============================] - 4s 45ms/step - loss: 4.9807e-04 - accuracy: 0.9989 - val_loss: 0.1562 - val_accuracy: 0.8813\n",
            "Epoch 390/400\n",
            "91/91 [==============================] - 4s 45ms/step - loss: 6.1128e-04 - accuracy: 0.9987 - val_loss: 0.1442 - val_accuracy: 0.8785\n",
            "Epoch 391/400\n",
            "91/91 [==============================] - 4s 46ms/step - loss: 4.3758e-04 - accuracy: 0.9986 - val_loss: 0.1438 - val_accuracy: 0.8805\n",
            "Epoch 392/400\n",
            "91/91 [==============================] - 4s 45ms/step - loss: 4.9915e-04 - accuracy: 0.9985 - val_loss: 0.1325 - val_accuracy: 0.8817\n",
            "Epoch 393/400\n",
            "91/91 [==============================] - 4s 45ms/step - loss: 5.2461e-04 - accuracy: 0.9984 - val_loss: 0.1298 - val_accuracy: 0.8781\n",
            "Epoch 394/400\n",
            "91/91 [==============================] - 4s 45ms/step - loss: 4.0362e-04 - accuracy: 0.9987 - val_loss: 0.1333 - val_accuracy: 0.8849\n",
            "Epoch 395/400\n",
            "91/91 [==============================] - 4s 45ms/step - loss: 3.9228e-04 - accuracy: 0.9985 - val_loss: 0.1404 - val_accuracy: 0.8807\n",
            "Epoch 396/400\n",
            "91/91 [==============================] - 4s 45ms/step - loss: 3.3610e-04 - accuracy: 0.9984 - val_loss: 0.1415 - val_accuracy: 0.8823\n",
            "Epoch 397/400\n",
            "91/91 [==============================] - 4s 45ms/step - loss: 4.1189e-04 - accuracy: 0.9985 - val_loss: 0.1402 - val_accuracy: 0.8767\n",
            "Epoch 398/400\n",
            "91/91 [==============================] - 4s 45ms/step - loss: 5.7049e-04 - accuracy: 0.9990 - val_loss: 0.1276 - val_accuracy: 0.8815\n",
            "Epoch 399/400\n",
            "91/91 [==============================] - 4s 45ms/step - loss: 3.1443e-04 - accuracy: 0.9989 - val_loss: 0.1337 - val_accuracy: 0.8823\n",
            "Epoch 400/400\n",
            "91/91 [==============================] - 4s 45ms/step - loss: 3.9037e-04 - accuracy: 0.9991 - val_loss: 0.1325 - val_accuracy: 0.8811\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "geoXWoLissqg",
        "outputId": "4ec59dd3-1bc2-4a44-c6ac-af566af5208e"
      },
      "source": [
        "y_test = testY['gender']\n",
        "loss, acc = lcnn.evaluate(x_test, y_test)\n",
        "pred=lcnn.predict(x_test)\n",
        "print(f'Accuracy : {acc*100}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "75/75 [==============================] - 1s 9ms/step - loss: 0.1312 - accuracy: 0.8843\n",
            "Accuracy : 88.43393921852112\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GnC-c3pGHt08"
      },
      "source": [
        "from keras.models import load_model\n",
        "lcnn.save(\"/content/drive/MyDrive/DAI/lcnn_400_focal.h5\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rVttCQyZZjr0",
        "outputId": "32875e9f-7fb5-4617-f98a-4f9c65808fac"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v-JIGDopI74L",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4a21376b-2363-4bce-962c-8de1535dc2b4"
      },
      "source": [
        "pred"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.00155018, 0.9984498 ],\n",
              "       [0.7118429 , 0.28815714],\n",
              "       [0.7958826 , 0.20411745],\n",
              "       ...,\n",
              "       [0.97597337, 0.02402664],\n",
              "       [0.9986286 , 0.00137137],\n",
              "       [0.00115201, 0.99884796]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GiVKS54axqTK"
      },
      "source": [
        "pred_class = []\n",
        "for i in range(len(pred)):\n",
        "  if pred[i][0] > pred[i][1]:\n",
        "    pred_class.append(0)\n",
        "  else:\n",
        "    pred_class.append(1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aQQNlTo3ju-e",
        "outputId": "15adec58-5f06-4f74-9de6-22b62a7cbdfa"
      },
      "source": [
        "pred[0][0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0015501849"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "khIduro1oISz"
      },
      "source": [
        "df_test = pd.DataFrame()\n",
        "df_test['gender'] = sample_test\n",
        "df_test['age'] = testY['age']\n",
        "df_test['ethnicity'] = testY['ethnicity']\n",
        "df_test['predicted'] = pred_class\n",
        "#df_test['input'] = testX\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "EQKlVKVPwo2E",
        "outputId": "c4d0f090-280b-41c0-8cea-1a73d245ec06"
      },
      "source": [
        "df_test"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>gender</th>\n",
              "      <th>age</th>\n",
              "      <th>ethnicity</th>\n",
              "      <th>predicted</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>28 - 56</td>\n",
              "      <td>White</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>28 - 56</td>\n",
              "      <td>Black</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>56 - 24</td>\n",
              "      <td>Asian</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>0 - 28</td>\n",
              "      <td>White</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>56 - 24</td>\n",
              "      <td>White</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2364</th>\n",
              "      <td>0</td>\n",
              "      <td>0 - 28</td>\n",
              "      <td>Indian</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2365</th>\n",
              "      <td>0</td>\n",
              "      <td>56 - 24</td>\n",
              "      <td>White</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2366</th>\n",
              "      <td>0</td>\n",
              "      <td>0 - 28</td>\n",
              "      <td>White</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2367</th>\n",
              "      <td>0</td>\n",
              "      <td>56 - 24</td>\n",
              "      <td>Black</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2368</th>\n",
              "      <td>1</td>\n",
              "      <td>0 - 28</td>\n",
              "      <td>Asian</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2369 rows  4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      gender      age ethnicity  predicted\n",
              "0          1  28 - 56     White          1\n",
              "1          1  28 - 56     Black          0\n",
              "2          0  56 - 24     Asian          0\n",
              "3          1   0 - 28     White          1\n",
              "4          1  56 - 24     White          1\n",
              "...      ...      ...       ...        ...\n",
              "2364       0   0 - 28    Indian          0\n",
              "2365       0  56 - 24     White          0\n",
              "2366       0   0 - 28     White          0\n",
              "2367       0  56 - 24     Black          0\n",
              "2368       1   0 - 28     Asian          1\n",
              "\n",
              "[2369 rows x 4 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sn8z1fiPzMiE"
      },
      "source": [
        "l = df_test['age'].unique()\n",
        "gk = df_test.groupby('age')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 258
        },
        "id": "yGlPFi8hzoxg",
        "outputId": "44c51618-77a7-4774-abc9-74e5500b6046"
      },
      "source": [
        "acc = []\n",
        "group_age = []\n",
        "count = []\n",
        "for i in range(len(l)):\n",
        "    df_test_age=gk.get_group(l[i])\n",
        "    accuracy = accuracy_score(df_test_age['predicted'], df_test_age['gender'])\n",
        "    cm = confusion_matrix(df_test_age['predicted'], df_test_age['gender'])\n",
        "    acc.append(accuracy)\n",
        "    group_age.append(l[i])\n",
        "    count.append(len(df_test_age))\n",
        "    print(\"Age group\", l[i])\n",
        "    #print(accuracy)\n",
        "    print(\"CM\",cm)\n",
        "    print()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-e713a0a87e41>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mgroup_age\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mcount\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mdf_test_age\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_test_age\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'predicted'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_test_age\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'gender'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'l' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hRPEx1-_zqwQ",
        "outputId": "49d6a8a5-a244-4456-9f0d-598e54d163e4"
      },
      "source": [
        "df_age_result = pd.DataFrame()\n",
        "df_age_result['age'] = group_age\n",
        "df_age_result['acc'] = acc\n",
        "df_age_result['count'] = count\n",
        "print(df_age_result)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "        age       acc  count\n",
            "0   28 - 56  0.945000   1000\n",
            "1   56 - 24  0.897764    313\n",
            "2    0 - 28  0.825743   1010\n",
            "3  84 - 116  0.760870     46\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2K8d3v6uzstO"
      },
      "source": [
        "l = df_test['ethnicity'].unique()\n",
        "#print(l)\n",
        "gk1 = df_test.groupby('ethnicity')\n",
        "acc = []\n",
        "group_race = []\n",
        "count = []\n",
        "for i in range(len(l)):\n",
        "    df_test_race=gk1.get_group(l[i])\n",
        "    accuracy = accuracy_score(df_test_race['predicted'], df_test_race['gender'])\n",
        "    cm = confusion_matrix(df_test_race['predicted'], df_test_race['gender'])\n",
        "    acc.append(accuracy)\n",
        "    group_race.append(l[i])\n",
        "    count.append(len(df_test_race))\n",
        "    #print(l[i])\n",
        "    #print(accuracy)\n",
        "    #print(cm)\n",
        "    df_test_race = pd.DataFrame()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Nm6xr7HzzLO",
        "outputId": "64f70db5-e869-4c4e-eadc-b2c75e8fffe3"
      },
      "source": [
        "df_race_result = pd.DataFrame()\n",
        "df_race_result['race'] = group_race\n",
        "df_race_result['acc'] = acc\n",
        "df_race_result['count'] = count\n",
        "print(df_race_result)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     race       acc  count\n",
            "0   White  0.878431   1020\n",
            "1   Black  0.929864    442\n",
            "2   Asian  0.845238    336\n",
            "3   Other  0.869565    161\n",
            "4  Indian  0.887805    410\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zxx4E1Zxz8TD"
      },
      "source": [
        "# ROC"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wq0hRmW4z064"
      },
      "source": [
        "def get_values(y_true, y_prob, thresholds):\n",
        "\n",
        "    fpr = []\n",
        "    tpr = []\n",
        "    precision = []\n",
        "    far = []\n",
        "    frr = []\n",
        "    for threshold in thresholds:\n",
        "\n",
        "        y_pred = np.where(y_prob >= threshold, 1, 0)\n",
        "\n",
        "        # fp = np.sum((y_pred == 1) & (y_true == 0))\n",
        "        # tp = np.sum((y_pred == 1) & (y_true == 1))\n",
        "\n",
        "        # fn = np.sum((y_pred == 0) & (y_true == 1))\n",
        "        # tn = np.sum((y_pred == 0) & (y_true == 0))\n",
        "        tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
        "\n",
        "        fpr.append(fp / (fp + tn))\n",
        "        tpr.append(tp / (tp + fn))\n",
        "        precision.append(tp / (tp + fp))\n",
        "        far.append(fp / (fp + tn))\n",
        "        frr.append(fn / (tp + fn))\n",
        "    return [fpr, tpr, precision, tpr, far, frr]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6AR6hzPWz9Mu"
      },
      "source": [
        "thresholds = []\n",
        "i = 0.0001\n",
        "while i < 1:\n",
        "  thresholds.append(i)\n",
        "  i += 0.0001"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3DHjMqEbz_Wj"
      },
      "source": [
        "y_test = sample_test\n",
        "y_prob = pred"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o6A7tJmO0CAc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4de6ebf9-afa0-4b4c-b499-17f649933e0e"
      },
      "source": [
        "fpr1, tpr1, precision1, recall1, far1, frr1 = get_values(y_test, y_prob[:, 1], thresholds)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:21: RuntimeWarning: invalid value encountered in long_scalars\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bXzPHubx0GBP"
      },
      "source": [
        "# Precision-Recall curve"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 314
        },
        "id": "30HhrI9C0E0X",
        "outputId": "092ab4b4-5117-4ccb-fc18-7bf624f97206"
      },
      "source": [
        "plt.plot(recall1, precision1)\n",
        "plt.xlabel('Recall')\n",
        "plt.ylabel('Precision')\n",
        "plt.title(\"LCNN Precision-Recall curve at focal loss\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'LCNN Precision-Recall curve at focal loss')"
            ]
          },
          "metadata": {},
          "execution_count": 71
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 284
        },
        "id": "yqL-KP0-0Mfg",
        "outputId": "4abfb4ec-7c14-425b-edbb-0de0fbf97f46"
      },
      "source": [
        "plt.plot(far1)\n",
        "plt.plot(frr1)\n",
        "plt.legend(['FAR', 'FRR'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7fde0f6e80d0>"
            ]
          },
          "metadata": {},
          "execution_count": 62
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WmEC82CB0PWv",
        "outputId": "490015ad-2eb9-478e-9404-955d0c5a1b17"
      },
      "source": [
        "index = -1\n",
        "ans = 1000\n",
        "t = []\n",
        "for i in range(len(far1)):\n",
        "  if ans > abs(far1[i]-frr1[i]):\n",
        "    ans = abs(far1[i]-frr1[i])\n",
        "    index = i\n",
        "print(ans, index, far1[index], frr1[index])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.00034791039881368335 4276 0.11295681063122924 0.11330472103004292\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 314
        },
        "id": "EgS8I7cH0SXH",
        "outputId": "74cdc73a-7a09-4610-bddf-63f0040c169e"
      },
      "source": [
        "\n",
        "from matplotlib import pyplot as plt\n",
        "plt.plot(fpr1, tpr1, marker='.', label='Male')\n",
        "pyplot.plot([0, 1], [0, 1], linestyle='--', label='Female')\n",
        "plt.title(\"LCNN ROC curve at focal loss\")\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.legend()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7fdd99af5150>"
            ]
          },
          "metadata": {},
          "execution_count": 70
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HhG4IsWaNzkY"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}